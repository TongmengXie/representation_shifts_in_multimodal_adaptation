{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7436c180",
   "metadata": {},
   "source": [
    "# LinearProbes_brightness\n",
    "\n",
    "Pairwise-controlled linear probing for **brightness** (−50% vs +50%) using COCO val2017 and PaliGemma.\n",
    "\n",
    "> Labels: 0 = darker (−50%), 1 = brighter (+50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d322074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 0. Config & Setup\n",
    "# Adjust paths as needed. This notebook uses COCO **val2017** only.\n",
    "\n",
    "import os, random, json, io\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "\n",
    "# --- Paths (edit these to match your local files) ---\n",
    "ANNO_DIR = '../data/annotations_trainval2017/annotations'\n",
    "IMG_DIR  = '../data/val2017'               # COCO val2017 images\n",
    "OUT_IMG_DIR = '../data/brightness_pairs'   # directory to save brightness-perturbed images\n",
    "OUT_CSV = '../data/brightness_dataset.csv' # CSV with variants & labels\n",
    "OUTPUT_DIR = '../output/brightness_probe_pairwise'\n",
    "os.makedirs(OUT_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Probe params\n",
    "N_GROUPS = 200                # number of base images to sample (each yields 2 variants)\n",
    "PAD_TO_MAX = 64               # text max length when extracting LM activations\n",
    "MODE = \"lm\"                   # 'lm' (1152 vs 1152) or 'raw' (2304 vs 1152); for brightness we usually use LM\n",
    "MODEL_NAME = 'google/paligemma2-3b-pt-224'\n",
    "\n",
    "print('Config loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37f4e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing scikit-learn ...\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/py311/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Pillow ...\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/py311/lib/python3.11/site-packages (11.3.0)\n",
      "Environment ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Environment Check\n",
    "\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkg):\n",
    "    try:\n",
    "        __import__(pkg.split('==')[0].split('[')[0].replace('-', '_'))\n",
    "    except Exception:\n",
    "        print(f'Installing {pkg} ...')\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "# Ensure deps (comment out if you manage env separately)\n",
    "for pkg in [\n",
    "    \"pycocotools\",\n",
    "    \"transformers>=4.41.0\",\n",
    "    \"torch\",\n",
    "    \"pandas\",\n",
    "    \"scikit-learn\",\n",
    "    \"matplotlib\",\n",
    "    \"Pillow\",\n",
    "]:\n",
    "    try:\n",
    "        __import__(pkg.split('>=')[0].split('==')[0])\n",
    "    except Exception as e:\n",
    "        pip_install(pkg)\n",
    "\n",
    "print('Environment ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91172f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_id</th>\n",
       "      <th>orig_file_name</th>\n",
       "      <th>variant_file_name</th>\n",
       "      <th>variant_path</th>\n",
       "      <th>variant</th>\n",
       "      <th>label</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364884</td>\n",
       "      <td>000000364884.jpg</td>\n",
       "      <td>000000364884_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000364884_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>A person in a snow sporting event  is going ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>364884</td>\n",
       "      <td>000000364884.jpg</td>\n",
       "      <td>000000364884_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000364884_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>A person in a snow sporting event  is going ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140840</td>\n",
       "      <td>000000140840.jpg</td>\n",
       "      <td>000000140840_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000140840_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>Various kites near the ground in a field.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140840</td>\n",
       "      <td>000000140840.jpg</td>\n",
       "      <td>000000140840_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000140840_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>Various kites near the ground in a field.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>353096</td>\n",
       "      <td>000000353096.jpg</td>\n",
       "      <td>000000353096_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000353096_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>A computer with an image of lighting on the sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>546976</td>\n",
       "      <td>000000546976.jpg</td>\n",
       "      <td>000000546976_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000546976_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>A man riding on the back of a motorcycle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>262895</td>\n",
       "      <td>000000262895.jpg</td>\n",
       "      <td>000000262895_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000262895_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>A fairly curmudgeonly looking old gentleman gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>262895</td>\n",
       "      <td>000000262895.jpg</td>\n",
       "      <td>000000262895_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000262895_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>A fairly curmudgeonly looking old gentleman gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>474881</td>\n",
       "      <td>000000474881.jpg</td>\n",
       "      <td>000000474881_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000474881_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>The elk have horns and are eating grass.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>474881</td>\n",
       "      <td>000000474881.jpg</td>\n",
       "      <td>000000474881_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000474881_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>The elk have horns and are eating grass.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     base_id    orig_file_name        variant_file_name  \\\n",
       "0     364884  000000364884.jpg    000000364884_dark.jpg   \n",
       "1     364884  000000364884.jpg  000000364884_bright.jpg   \n",
       "2     140840  000000140840.jpg    000000140840_dark.jpg   \n",
       "3     140840  000000140840.jpg  000000140840_bright.jpg   \n",
       "4     353096  000000353096.jpg    000000353096_dark.jpg   \n",
       "..       ...               ...                      ...   \n",
       "395   546976  000000546976.jpg  000000546976_bright.jpg   \n",
       "396   262895  000000262895.jpg    000000262895_dark.jpg   \n",
       "397   262895  000000262895.jpg  000000262895_bright.jpg   \n",
       "398   474881  000000474881.jpg    000000474881_dark.jpg   \n",
       "399   474881  000000474881.jpg  000000474881_bright.jpg   \n",
       "\n",
       "                                         variant_path variant  label  \\\n",
       "0      ../data/brightness_pairs/000000364884_dark.jpg    dark      0   \n",
       "1    ../data/brightness_pairs/000000364884_bright.jpg  bright      1   \n",
       "2      ../data/brightness_pairs/000000140840_dark.jpg    dark      0   \n",
       "3    ../data/brightness_pairs/000000140840_bright.jpg  bright      1   \n",
       "4      ../data/brightness_pairs/000000353096_dark.jpg    dark      0   \n",
       "..                                                ...     ...    ...   \n",
       "395  ../data/brightness_pairs/000000546976_bright.jpg  bright      1   \n",
       "396    ../data/brightness_pairs/000000262895_dark.jpg    dark      0   \n",
       "397  ../data/brightness_pairs/000000262895_bright.jpg  bright      1   \n",
       "398    ../data/brightness_pairs/000000474881_dark.jpg    dark      0   \n",
       "399  ../data/brightness_pairs/000000474881_bright.jpg  bright      1   \n",
       "\n",
       "                                               caption  \n",
       "0    A person in a snow sporting event  is going ra...  \n",
       "1    A person in a snow sporting event  is going ra...  \n",
       "2            Various kites near the ground in a field.  \n",
       "3            Various kites near the ground in a field.  \n",
       "4    A computer with an image of lighting on the sc...  \n",
       "..                                                 ...  \n",
       "395          A man riding on the back of a motorcycle.  \n",
       "396  A fairly curmudgeonly looking old gentleman gr...  \n",
       "397  A fairly curmudgeonly looking old gentleman gr...  \n",
       "398          The elk have horns and are eating grass.   \n",
       "399          The elk have horns and are eating grass.   \n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Already creataed data set in \"create_datasets.ipyb\"\n",
    "# # ## 2. Create Brightness-Controlled Dataset (Pairs per Base Image)\n",
    "# # - Picks N_GROUPS images from COCO val2017 with at least one caption\n",
    "# # - Creates two variants per base image: 0.5x (label=0) and 1.5x (label=1)\n",
    "# # - Saves modified images to OUT_IMG_DIR and records a CSV with captions\n",
    "\n",
    "# from pycocotools.coco import COCO\n",
    "# from PIL import Image, ImageEnhance\n",
    "# import pandas as pd\n",
    "\n",
    "# coco = COCO(f\"{ANNO_DIR}/instances_val2017.json\")\n",
    "# cap  = COCO(f\"{ANNO_DIR}/captions_val2017.json\")\n",
    "\n",
    "# # map: image_id -> [captions]\n",
    "# caps_by_img = {}\n",
    "# for a in cap.dataset[\"annotations\"]:\n",
    "#     caps_by_img.setdefault(a[\"image_id\"], []).append(a[\"caption\"])\n",
    "\n",
    "# # choose base images with captions\n",
    "# img_ids = [iid for iid in coco.getImgIds() if caps_by_img.get(iid)]\n",
    "# random.shuffle(img_ids)\n",
    "# img_ids = img_ids[:N_GROUPS]\n",
    "\n",
    "# rows = []\n",
    "# BRIGHT_FACTORS = [(0.5, \"dark\", 0), (1.5, \"bright\", 1)]  # (factor, suffix, label)\n",
    "\n",
    "# for img in coco.loadImgs(img_ids):\n",
    "#     base_id = Path(img[\"file_name\"]).stem  # e.g., 000000123456\n",
    "#     src_path = Path(IMG_DIR) / img[\"file_name\"]\n",
    "#     if not src_path.exists():\n",
    "#         continue\n",
    "\n",
    "#     caption = random.choice(caps_by_img.get(img[\"id\"], [\"\"]))\n",
    "\n",
    "#     with Image.open(src_path).convert(\"RGB\") as im:\n",
    "#         enhancer = ImageEnhance.Brightness(im)\n",
    "#         for factor, suffix, label in BRIGHT_FACTORS:\n",
    "#             out_name = f\"{base_id}_{suffix}.jpg\"\n",
    "#             out_path = Path(OUT_IMG_DIR) / out_name\n",
    "#             enhancer.enhance(factor).save(out_path, quality=95)\n",
    "#             rows.append({\n",
    "#                 \"base_id\": base_id,\n",
    "#                 \"orig_file_name\": img[\"file_name\"],\n",
    "#                 \"variant_file_name\": out_name,\n",
    "#                 \"variant_path\": str(out_path),\n",
    "#                 \"variant\": suffix,\n",
    "#                 \"label\": label,\n",
    "#                 \"caption\": caption\n",
    "#             })\n",
    "\n",
    "# df_pairs = pd.DataFrame(rows)\n",
    "# df_pairs.to_csv(OUT_CSV, index=False)\n",
    "# print(f\"Saved {len(df_pairs)} rows ({len(df_pairs)//2} groups) -> {OUT_CSV}\")\n",
    "# df_pairs.head()\n",
    "import pandas as pd\n",
    "\n",
    "df_pairs = pd.read_csv(OUT_CSV)\n",
    "df_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9eba34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: google/paligemma2-3b-pt-224\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Load PaliGemma & Helpers\n",
    "\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoTokenizer, AutoModel\n",
    "from typing import List, Optional\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)\n",
    "\n",
    "# autocast / amp context\n",
    "class _amp_ctx:\n",
    "    def __init__(self, device='cuda', use_amp=True):\n",
    "        self.device = device\n",
    "        self.use_amp = use_amp and (device == 'cuda')\n",
    "    def __enter__(self):\n",
    "        if self.use_amp:\n",
    "            self.ctx = torch.autocast(device_type='cuda', dtype=torch.bfloat16)\n",
    "            self.ctx.__enter__()\n",
    "        else:\n",
    "            self.ctx = None\n",
    "        return self\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        if self.ctx is not None:\n",
    "            self.ctx.__exit__(exc_type, exc, tb)\n",
    "\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device).eval()\n",
    "print('Model loaded:', MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb690aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Activation Extraction (with pad_to_max + 'lm'/'raw' modes)\n",
    "\n",
    "# Returns list of arrays per layer: [N, seq_len, D]\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def get_acts_paligemma(\n",
    "    model, device,\n",
    "    model_name=MODEL_NAME,\n",
    "    *, filenames: Optional[List[str]] = None, text: Optional[List[str]] = None,\n",
    "    batch_size=32, use_amp=True, mode=\"lm\", pad_to_max=None\n",
    "):\n",
    "    if (text is not None) and (filenames is not None):\n",
    "        raise ValueError(\"Provide either text or image, not both.\")\n",
    "\n",
    "    feats = []\n",
    "    model.eval()\n",
    "\n",
    "    # IMAGE branch\n",
    "    if filenames is not None:\n",
    "        proc = AutoProcessor.from_pretrained(model_name)\n",
    "        if mode == \"raw\":\n",
    "            model.vision_tower.config.output_hidden_states = True\n",
    "        else:\n",
    "            model.language_model.config.output_hidden_states = True\n",
    "\n",
    "        with torch.inference_mode(), _amp_ctx(device, use_amp):\n",
    "            for i in range(0, len(filenames), batch_size):\n",
    "                fbatch = filenames[i:i+batch_size]\n",
    "                imgs = [Image.open(fp).convert(\"RGB\") for fp in fbatch]\n",
    "\n",
    "                if mode == \"raw\":\n",
    "                    enc = proc(images=imgs, text=[\"<image>\"]*len(imgs), return_tensors=\"pt\")\n",
    "                    px = enc[\"pixel_values\"].to(device, non_blocking=True)\n",
    "                    vout = model.vision_tower(pixel_values=px, output_hidden_states=True, return_dict=True)\n",
    "                    hs = vout.hidden_states  # tuple of layers: [B, seq, 2304]\n",
    "                else:\n",
    "                    enc = proc(images=imgs, text=[\"<image>\"]*len(imgs), return_tensors=\"pt\").to(device)\n",
    "                    out = model.language_model(**enc, output_hidden_states=True, return_dict=True)\n",
    "                    hs = out.hidden_states   # tuple: [B, seq, 1152]\n",
    "\n",
    "                feats.append([h.detach().cpu().float().numpy() for h in hs])\n",
    "                del hs, enc, imgs\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # TEXT branch\n",
    "    elif text is not None:\n",
    "        tok = AutoTokenizer.from_pretrained(model_name)\n",
    "        model.language_model.config.output_hidden_states = True\n",
    "\n",
    "        with torch.inference_mode(), _amp_ctx(device, use_amp):\n",
    "            for i in range(0, len(text), batch_size):\n",
    "                tbatch = text[i:i+batch_size]\n",
    "                enc = tok(\n",
    "                    tbatch, return_tensors=\"pt\",\n",
    "                    padding=\"max_length\" if pad_to_max else True,\n",
    "                    truncation=True, max_length=pad_to_max\n",
    "                ).to(device)\n",
    "\n",
    "                out = model.language_model(**enc, output_hidden_states=True, return_dict=True)\n",
    "                hs = out.hidden_states  # tuple: [B, seq, 1152]\n",
    "\n",
    "                feats.append([h.detach().cpu().float().numpy() for h in hs])\n",
    "                del hs, enc, out\n",
    "                torch.cuda.empty_cache()\n",
    "    else:\n",
    "        raise ValueError(\"Must provide either filenames or text.\")\n",
    "\n",
    "    # concatenate across batches per layer\n",
    "    n_layers = len(feats[0])\n",
    "    layerwise = []\n",
    "    for l in range(n_layers):\n",
    "        arrs = [batch[l] for batch in feats]    # list of [B, seq, D]\n",
    "        layerwise.append(np.concatenate(arrs, axis=0))  # [N, seq, D] (consistent seq if padded)\n",
    "\n",
    "    return layerwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf150f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train groups: 160, Test groups: 40\n",
      "Train rows: 320, Test rows: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  0 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer  1 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer  2 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer  3 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer  4 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer  5 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer  6 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer  7 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer  8 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer  9 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 10 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 11 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 12 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 13 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 14 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 15 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 16 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 17 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 18 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 19 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 20 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 21 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 22 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 23 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 24 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 25 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Layer 26 | Train 0.5000 | Test 0.5000 | F1 0.3333\n",
      "Saved results -> ../output/brightness_probe_pairwise/results.csv\n",
      "Saved plot -> ../output/brightness_probe_pairwise/accuracy_f1_curve.png\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Pairwise-Controlled Probing for Brightness\n",
    "\n",
    "# Split by base_id (group), extract activations for each variant, and run a linear probe per layer.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(OUT_CSV)  # columns: base_id, variant_path, label, caption, ...\n",
    "\n",
    "# group-wise split on base_id (prevents identity leakage)\n",
    "unique_ids = sorted(df['base_id'].unique())\n",
    "train_ids, test_ids = train_test_split(unique_ids, test_size=0.2, random_state=SEED)\n",
    "\n",
    "df_tr = df[df['base_id'].isin(train_ids)].reset_index(drop=True)\n",
    "df_te = df[df['base_id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train groups: {len(train_ids)}, Test groups: {len(test_ids)}\")\n",
    "print(f\"Train rows: {len(df_tr)}, Test rows: {len(df_te)}\")\n",
    "\n",
    "# extract (images only for brightness), LM space (so D=1152), mean-pool tokens per sample\n",
    "with torch.inference_mode():\n",
    "    img_layers_tr = get_acts_paligemma(\n",
    "        model, device, filenames=df_tr['variant_path'].tolist(),\n",
    "        mode=MODE, pad_to_max=None\n",
    "    )\n",
    "    img_layers_te = get_acts_paligemma(\n",
    "        model, device, filenames=df_te['variant_path'].tolist(),\n",
    "        mode=MODE, pad_to_max=None\n",
    "    )\n",
    "\n",
    "n_layers = len(img_layers_tr)\n",
    "layer_ix = list(range(n_layers))\n",
    "\n",
    "all_rows = []\n",
    "for layer in layer_ix:\n",
    "    X_tr = img_layers_tr[layer].mean(axis=1)  # [N_train, D]\n",
    "    y_tr = df_tr['label'].to_numpy()\n",
    "    X_te = img_layers_te[layer].mean(axis=1)  # [N_test, D]\n",
    "    y_te = df_te['label'].to_numpy()\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=SEED).fit(X_tr, y_tr)\n",
    "    yhat_tr = clf.predict(X_tr)\n",
    "    yhat_te = clf.predict(X_te)\n",
    "\n",
    "    tr_acc = accuracy_score(y_tr, yhat_tr)\n",
    "    te_acc = accuracy_score(y_te, yhat_te)\n",
    "    te_f1  = f1_score(y_te, yhat_te, average=\"macro\")\n",
    "\n",
    "    print(f\"Layer {layer:2d} | Train {tr_acc:.4f} | Test {te_acc:.4f} | F1 {te_f1:.4f}\")\n",
    "    all_rows.append({\"layer\": layer, \"train_acc\": tr_acc, \"test_acc\": te_acc, \"test_f1\": te_f1})\n",
    "\n",
    "# Save results and plot\n",
    "res_df = pd.DataFrame(all_rows)\n",
    "res_csv = str(Path(OUTPUT_DIR) / \"results.csv\")\n",
    "res_plot = str(Path(OUTPUT_DIR) / \"accuracy_f1_curve.png\")\n",
    "res_df.to_csv(res_csv, index=False)\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(res_df[\"layer\"], res_df[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(res_df[\"layer\"], res_df[\"test_acc\"],  label=\"Test Acc\")\n",
    "plt.plot(res_df[\"layer\"], res_df[\"test_f1\"],   label=\"Test F1\", linestyle=\"--\", marker=\"o\")\n",
    "# highlight layer 0\n",
    "if 0 in res_df[\"layer\"].values:\n",
    "    i0 = res_df.index[res_df[\"layer\"]==0][0]\n",
    "    plt.scatter([0], [res_df.loc[i0, \"test_acc\"]], s=60, edgecolors=\"k\", label=\"Layer 0 (Test Acc)\")\n",
    "plt.xlabel(\"Layer\"); plt.ylabel(\"Score\"); plt.title(\"Brightness Probe (Pairwise-Controlled)\")\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.savefig(res_plot, dpi=150); plt.close()\n",
    "\n",
    "print(f\"Saved results -> {res_csv}\\nSaved plot -> {res_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b54f7755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_id</th>\n",
       "      <th>orig_file_name</th>\n",
       "      <th>variant_file_name</th>\n",
       "      <th>variant_path</th>\n",
       "      <th>variant</th>\n",
       "      <th>label</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364884</td>\n",
       "      <td>000000364884.jpg</td>\n",
       "      <td>000000364884_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000364884_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>A person in a snow sporting event  is going ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>364884</td>\n",
       "      <td>000000364884.jpg</td>\n",
       "      <td>000000364884_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000364884_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>A person in a snow sporting event  is going ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140840</td>\n",
       "      <td>000000140840.jpg</td>\n",
       "      <td>000000140840_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000140840_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>Various kites near the ground in a field.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140840</td>\n",
       "      <td>000000140840.jpg</td>\n",
       "      <td>000000140840_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000140840_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>Various kites near the ground in a field.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>353096</td>\n",
       "      <td>000000353096.jpg</td>\n",
       "      <td>000000353096_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000353096_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>A computer with an image of lighting on the sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>571943</td>\n",
       "      <td>000000571943.jpg</td>\n",
       "      <td>000000571943_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000571943_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>A picture of a street light and sign showing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>262895</td>\n",
       "      <td>000000262895.jpg</td>\n",
       "      <td>000000262895_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000262895_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>A fairly curmudgeonly looking old gentleman gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>262895</td>\n",
       "      <td>000000262895.jpg</td>\n",
       "      <td>000000262895_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000262895_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>A fairly curmudgeonly looking old gentleman gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>474881</td>\n",
       "      <td>000000474881.jpg</td>\n",
       "      <td>000000474881_dark.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000474881_dark.jpg</td>\n",
       "      <td>dark</td>\n",
       "      <td>0</td>\n",
       "      <td>The elk have horns and are eating grass.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>474881</td>\n",
       "      <td>000000474881.jpg</td>\n",
       "      <td>000000474881_bright.jpg</td>\n",
       "      <td>../data/brightness_pairs/000000474881_bright.jpg</td>\n",
       "      <td>bright</td>\n",
       "      <td>1</td>\n",
       "      <td>The elk have horns and are eating grass.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     base_id    orig_file_name        variant_file_name  \\\n",
       "0     364884  000000364884.jpg    000000364884_dark.jpg   \n",
       "1     364884  000000364884.jpg  000000364884_bright.jpg   \n",
       "2     140840  000000140840.jpg    000000140840_dark.jpg   \n",
       "3     140840  000000140840.jpg  000000140840_bright.jpg   \n",
       "4     353096  000000353096.jpg    000000353096_dark.jpg   \n",
       "..       ...               ...                      ...   \n",
       "315   571943  000000571943.jpg  000000571943_bright.jpg   \n",
       "316   262895  000000262895.jpg    000000262895_dark.jpg   \n",
       "317   262895  000000262895.jpg  000000262895_bright.jpg   \n",
       "318   474881  000000474881.jpg    000000474881_dark.jpg   \n",
       "319   474881  000000474881.jpg  000000474881_bright.jpg   \n",
       "\n",
       "                                         variant_path variant  label  \\\n",
       "0      ../data/brightness_pairs/000000364884_dark.jpg    dark      0   \n",
       "1    ../data/brightness_pairs/000000364884_bright.jpg  bright      1   \n",
       "2      ../data/brightness_pairs/000000140840_dark.jpg    dark      0   \n",
       "3    ../data/brightness_pairs/000000140840_bright.jpg  bright      1   \n",
       "4      ../data/brightness_pairs/000000353096_dark.jpg    dark      0   \n",
       "..                                                ...     ...    ...   \n",
       "315  ../data/brightness_pairs/000000571943_bright.jpg  bright      1   \n",
       "316    ../data/brightness_pairs/000000262895_dark.jpg    dark      0   \n",
       "317  ../data/brightness_pairs/000000262895_bright.jpg  bright      1   \n",
       "318    ../data/brightness_pairs/000000474881_dark.jpg    dark      0   \n",
       "319  ../data/brightness_pairs/000000474881_bright.jpg  bright      1   \n",
       "\n",
       "                                               caption  \n",
       "0    A person in a snow sporting event  is going ra...  \n",
       "1    A person in a snow sporting event  is going ra...  \n",
       "2            Various kites near the ground in a field.  \n",
       "3            Various kites near the ground in a field.  \n",
       "4    A computer with an image of lighting on the sc...  \n",
       "..                                                 ...  \n",
       "315  A picture of a street light and sign showing t...  \n",
       "316  A fairly curmudgeonly looking old gentleman gr...  \n",
       "317  A fairly curmudgeonly looking old gentleman gr...  \n",
       "318          The elk have horns and are eating grass.   \n",
       "319          The elk have horns and are eating grass.   \n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
