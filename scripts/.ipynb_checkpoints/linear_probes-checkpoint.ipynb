{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95e8a867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T00:16:36.826649Z",
     "start_time": "2025-08-24T00:16:31.008957Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from pathlib import Path\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, PaliGemmaForConditionalGeneration\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "\n",
    "# from random import random\n",
    "import random\n",
    "def seed_everywhere(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(seed)    \n",
    "SEED = 42\n",
    "MAX_SEQ_LEN = 64 # location to truncate our inputs\n",
    "DEVICE_1 = 'cuda:1'\n",
    "DEVICE_2 = 'cuda:2' # the second GPU\n",
    "NUM_CLASSES = 0\n",
    "seed_everywhere(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7a98e",
   "metadata": {},
   "source": [
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0597dd2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T00:16:36.854028Z",
     "start_time": "2025-08-24T00:16:36.831203Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActivationDataset(Dataset):\n",
    "    \"\"\"Dataset for model activations with labels\"\"\"\n",
    "    def __init__(self, activations, labels):\n",
    "        self.activations = torch.tensor(activations, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.activations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.activations[idx], self.labels[idx]\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    \"\"\"Simple linear probe for classification\"\"\"\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class LinearProbingExperiment:\n",
    "    def __init__(self, model_name=\"gemma\", concept=\"animals\"):\n",
    "        self.model_name = model_name\n",
    "        self.concept = concept\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "#     def load_activations(self, file_path):\n",
    "#         \"\"\"Load activations from file (assuming numpy format)\"\"\"\n",
    "#         data = np.load(file_path, allow_pickle=True)\n",
    "#         return data['activations'], data['labels']\n",
    "    \n",
    "    def train_sklearn_probe(self,\n",
    "                             X_train: np.ndarray,\n",
    "                             y_train: np.ndarray,\n",
    "                             X_test: np.ndarray,\n",
    "                             y_test: np.ndarray,\n",
    "                             texts_test: list = None) -> tuple:\n",
    "        \"\"\"\n",
    "        Train a sklearn logistic regression probe on flattened activations,\n",
    "        and return the trained probe and a results dict including misclassified samples:\n",
    "        - train_acc, test_acc, classification_report\n",
    "        - y_test, y_pred\n",
    "        - misclassified: list of dicts with index, text, true_label, pred_label\n",
    "        \"\"\"\n",
    "        # Set random state for reproducibility\n",
    "        probe = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "\n",
    "        # Flatten sequence and hidden dimensions\n",
    "        n_train_samples = X_train.shape[0]\n",
    "        n_test_samples = X_test.shape[0]\n",
    "        X_train_flat = X_train.reshape(n_train_samples, -1)\n",
    "        X_test_flat = X_test.reshape(n_test_samples, -1)\n",
    "        print(f\"X_train_flat shape: {X_train_flat.shape}\")\n",
    "        print(f\"y_train shape: {len(y_train)}\")\n",
    "        print(f\"X_test_flat shape: {X_test_flat.shape}\")\n",
    "        print(f\"y_test shape: {len(y_test)}\")\n",
    "\n",
    "        # Fit probe\n",
    "        probe.fit(X_train_flat, y_train)\n",
    "\n",
    "        # Predict\n",
    "        train_pred = probe.predict(X_train_flat)\n",
    "        test_pred = probe.predict(X_test_flat)\n",
    "\n",
    "        # Compute metrics\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "        test_acc = accuracy_score(y_test, test_pred)\n",
    "        report = classification_report(y_test, test_pred)\n",
    "\n",
    "        # Build results dict\n",
    "        results = {\n",
    "            'train_acc': train_acc,\n",
    "            'test_acc': test_acc,\n",
    "            'classification_report': report,\n",
    "            'y_test': y_test.tolist() if hasattr(y_test, 'tolist') else list(y_test),\n",
    "            'y_pred': test_pred.tolist(),\n",
    "        }\n",
    "\n",
    "        # Collect misclassified samples\n",
    "        misclassified = []\n",
    "        if texts_test is not None:\n",
    "            for idx, (true_label, pred_label) in enumerate(zip(y_test, test_pred)):\n",
    "                if true_label != pred_label:\n",
    "                    misclassified.append({\n",
    "                        'index': idx,\n",
    "                        'text': texts_test[idx],\n",
    "                        'true_label': int(true_label),\n",
    "                        'pred_label': int(pred_label)\n",
    "                    })\n",
    "        results['misclassified'] = misclassified\n",
    "\n",
    "        return probe, results\n",
    "    \n",
    "    def train_torch_probe(self, X_train, y_train, X_test, y_test, epochs=100):\n",
    "        \"\"\"Train PyTorch linear probe\"\"\"\n",
    "        input_dim = X_train.shape[0] # is this \"how many text snppets\"?\n",
    "#         num_classes = len(np.unique(y_train)) \n",
    "        num_classes = NUM_CLASSES # let's do binary classifier\n",
    "    # TODO: let's imitate sigmoid\n",
    "        train_dataset = ActivationDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        probe = LinearProbe(input_dim, num_classes).to(self.device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(probe.parameters(), lr=0.001)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            probe.train()\n",
    "            total_loss = 0\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x, batch_y = batch_x.to(self.device), batch_y.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = probe(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if epoch % 20 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        \n",
    "        # Evaluation\n",
    "        probe.eval()\n",
    "        with torch.no_grad():\n",
    "            X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(self.device)\n",
    "            test_outputs = probe(X_test_tensor)\n",
    "            test_pred = torch.argmax(test_outputs, dim=1).cpu().numpy()\n",
    "            \n",
    "            X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(self.device)\n",
    "            train_outputs = probe(X_train_tensor)\n",
    "            train_pred = torch.argmax(train_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        results = {\n",
    "            'train_acc': accuracy_score(y_train, train_pred),\n",
    "            'test_acc': accuracy_score(y_test, test_pred),\n",
    "            'classification_report': classification_report(y_test, test_pred)\n",
    "        }\n",
    "        \n",
    "        return probe, results\n",
    "    \n",
    "    def run_experiment(self, gemma_activations, gemma_labels, \n",
    "                      polygemma_activations, polygemma_labels):\n",
    "        \"\"\"Run complete probing experiment\"\"\"\n",
    "        print(f\"Running linear probing experiment: {self.concept}\")\n",
    "        print(f\"Gemma training data: {gemma_activations.shape}\")\n",
    "        print(f\"PolyGemma test data: {polygemma_activations.shape}\")\n",
    "        \n",
    "        # Train on Gemma, test on PolyGemma\n",
    "        results = {}\n",
    "    \n",
    "        \n",
    "        # sklearn probe\n",
    "        print(\"\\n--- Training sklearn probe ---\")\n",
    "        # Do the split!\n",
    "        gemma_activations_train, _, gemma_labels_train, _  = train_test_split(gemma_activations, gemma_labels, test_size=0.2, random_state=SEED)\n",
    "        _, polygemma_activations_test, _, polygemma_labels_test = train_test_split(polygemma_activations, polygemma_labels, test_size=0.2, random_state=SEED)\n",
    "        print(f\"size of gemma_activations_train: {gemma_activations_train.shape}, size of gemma_labels_train: {len(gemma_labels_train)}\")\n",
    "        print(f\"size of polygemma_activations_test: {polygemma_activations_test.shape}, size of polygemma_labels_test: {len(polygemma_labels_test)}\")\n",
    "        try:\n",
    "            gemma_activations_train = gemma_activations_train.cpu()\n",
    "            polygemma_activations_test = polygemma_activations_test.cpu()\n",
    "        except:\n",
    "            pass\n",
    "        sklearn_probe, sklearn_results = self.train_sklearn_probe(\n",
    "            gemma_activations_train, gemma_labels_train, # train\n",
    "            polygemma_activations_test, polygemma_labels_test # test\n",
    "        )\n",
    "        results['sklearn'] = sklearn_results\n",
    "        \n",
    "#         # PyTorch probe\n",
    "#         print(\"\\n--- Training PyTorch probe ---\")\n",
    "#         torch_probe, torch_results = self.train_torch_probe(\n",
    "#             gemma_activations, gemma_labels, # train\n",
    "#             polygemma_activations, polygemma_labels # test\n",
    "#         )\n",
    "#         results['torch'] = torch_results\n",
    "        \n",
    "        return sklearn_probe, results\n",
    "    \n",
    "    def save_results(self, results, output_path):\n",
    "        \"\"\"Save experiment results\"\"\"\n",
    "        output_path = Path(output_path)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Convert numpy types to Python types for JSON serialization\n",
    "        def convert_numpy(obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            return obj\n",
    "        \n",
    "        json_results = json.loads(json.dumps(results, default=convert_numpy))\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(json_results, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a8ba5",
   "metadata": {},
   "source": [
    "# synth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9af19901",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T00:16:36.861453Z",
     "start_time": "2025-08-24T00:16:36.855828Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Synthetic text data for cat/dog classification\n",
    "# text = [\n",
    "#     # Cat examples (label 0)\n",
    "#     \"The fluffy cat purred softly on the windowsill, watching birds outside.\",\n",
    "#     \"My kitten loves to chase the red laser pointer around the living room.\",\n",
    "#     \"The orange tabby cat stretched lazily in the warm afternoon sunlight.\",\n",
    "#     \"She adopted a rescue cat from the local animal shelter last week.\",\n",
    "#     \"The cat's whiskers twitched as it stalked the toy mouse across the floor.\",\n",
    "#     \"Fluffy meowed loudly when her food bowl was empty this morning.\",\n",
    "#     \"The black cat gracefully jumped onto the kitchen counter with ease.\",\n",
    "#     \"My feline friend enjoys napping in cardboard boxes all day long.\",\n",
    "#     \"The cat's green eyes glowed mysteriously in the dim moonlight tonight.\",\n",
    "#     \"Her pet cat brings dead mice to the doorstep every morning.\",\n",
    "#     \"The Siamese cat has the most beautiful blue eyes I've ever seen.\",\n",
    "#     \"Tom cat climbed up the tall oak tree to escape the neighborhood dogs.\",\n",
    "#     \"The veterinarian said the kitten needs its vaccinations next month.\",\n",
    "#     \"My cat purrs so loudly it sounds like a tiny motor running.\",\n",
    "#     \"The calico cat had three adorable kittens in the barn yesterday.\",\n",
    "#     \"She trained her cat to use the toilet instead of a litter box.\",\n",
    "#     \"The Persian cat's long fur requires daily brushing to prevent matting.\",\n",
    "#     \"My indoor cat watches wildlife documentaries on TV with great interest.\",\n",
    "#     \"The stray cat finally trusted me enough to eat from my hand.\",\n",
    "#     \"Her cat knocked over the expensive vase while chasing a butterfly.\",\n",
    "    \n",
    "#     # Dog examples (label 1)\n",
    "#     \"The golden retriever barked excitedly when his owner came home today.\",\n",
    "#     \"My dog loves to fetch tennis balls in the backyard every afternoon.\",\n",
    "#     \"The small puppy wagged its tail when meeting new people yesterday.\",\n",
    "#     \"She takes her German shepherd for long walks in the park.\",\n",
    "#     \"The dog's tail wagged furiously when it saw the treat jar.\",\n",
    "#     \"Max barked at the mailman who comes by every morning.\",\n",
    "#     \"The border collie herded the sheep expertly across the green field.\",\n",
    "#     \"My canine companion loves swimming in the lake during hot summers.\",\n",
    "#     \"The dog trainer taught the puppy basic commands like sit and stay.\",\n",
    "#     \"Her loyal dog waited patiently outside the grocery store for her.\",\n",
    "#     \"The beagle's nose led it straight to the hidden treats upstairs.\",\n",
    "#     \"My dog howls along with the sirens from passing fire trucks.\",\n",
    "#     \"The veterinarian recommended a special diet for the overweight bulldog.\",\n",
    "#     \"The rescue dog was nervous but gradually warmed up to us.\",\n",
    "#     \"My puppy chewed up my favorite pair of running shoes yesterday.\",\n",
    "#     \"The dog park was crowded with excited pups playing together today.\",\n",
    "#     \"Her service dog helps her navigate safely through busy city streets.\",\n",
    "#     \"The hunting dog pointed steadily at the birds hiding in bushes.\",\n",
    "#     \"My dog greets every visitor with enthusiastic tail wagging and jumping.\",\n",
    "#     \"The old dog slept peacefully by the fireplace on cold nights.\",\n",
    "    \n",
    "#     # Neutral/other examples (label 2) - neither cats nor dogs\n",
    "#     \"The morning sun cast beautiful shadows across the empty parking lot.\",\n",
    "#     \"She enjoyed reading mystery novels while drinking her evening tea.\",\n",
    "#     \"The mathematics professor explained complex equations on the whiteboard clearly.\",\n",
    "#     \"Fresh vegetables from the farmers market made an excellent dinner tonight.\",\n",
    "#     \"The old library contained thousands of books on various subjects.\",\n",
    "#     \"He repaired the broken bicycle tire using tools from the garage.\",\n",
    "#     \"The weather forecast predicted rain for the entire weekend ahead.\",\n",
    "#     \"Students gathered in the cafeteria to discuss their upcoming project.\",\n",
    "#     \"The concert featured amazing performances by local musicians and bands.\",\n",
    "#     \"She planted colorful flowers in her garden beds this spring.\",\n",
    "#     \"The computer program crashed unexpectedly during the important presentation today.\",\n",
    "#     \"Ocean waves crashed against the rocky cliffs during the storm.\",\n",
    "#     \"The chef prepared an elaborate feast for the wedding celebration.\",\n",
    "#     \"Mountains covered in snow looked majestic against the clear sky.\",\n",
    "#     \"The museum displayed artifacts from ancient civilizations throughout history.\",\n",
    "#     \"Traffic was heavy on the highway during rush hour yesterday.\",\n",
    "#     \"The smartphone battery died right before the important phone call.\",\n",
    "#     \"Autumn leaves fell gently from the trees in vibrant colors.\",\n",
    "#     \"The construction workers finished building the new bridge ahead of schedule.\",\n",
    "#     \"She studied diligently for her final exams in the quiet library.\"\n",
    "# ]\n",
    "\n",
    "# # Corresponding labels: 0=cat, 1=dog, 2=neutral\n",
    "# labels = [\n",
    "#     # Cat labels (0)\n",
    "#     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#     # Dog labels (1) \n",
    "#     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#     # Neutral labels (2)\n",
    "#     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
    "# ]\n",
    "\n",
    "# # Verify data consistency\n",
    "# print(f\"Total texts: {len(text)}\")\n",
    "# print(f\"Total labels: {len(labels)}\")\n",
    "# print(f\"Cat examples: {labels.count(0)}\")\n",
    "# print(f\"Dog examples: {labels.count(1)}\")\n",
    "# print(f\"Neutral examples: {labels.count(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c89e8",
   "metadata": {},
   "source": [
    "# COCO annotations & images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afaf27b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T00:16:37.311926Z",
     "start_time": "2025-08-24T00:16:36.863962Z"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_DIR = '../data'\n",
    "\n",
    "cat_df = pd.read_csv(f'{SAVE_DIR}/coco_val2017_cat_binary_with_captions_balanced.csv')\n",
    "cat_df = cat_df.sample(n=min(len(cat_df), 1000), random_state=SEED)\n",
    "\n",
    "dog_df = pd.read_csv(f'{SAVE_DIR}/coco_val2017_dog_binary_with_captions_balanced.csv')\n",
    "dog_df = dog_df.sample(n=min(len(dog_df), 1000), random_state=SEED)\n",
    "\n",
    "human_df = pd.read_csv(f'{SAVE_DIR}/coco_val2017_human_binary_with_captions_balanced.csv')\n",
    "human_df = human_df.sample(n=min(len(human_df), 1000), random_state=SEED)\n",
    "\n",
    "cat_df.captions = cat_df.captions.apply(lambda x:eval(x)[0])\n",
    "dog_df.captions = dog_df.captions.apply(lambda x:eval(x)[0])\n",
    "human_df.captions = human_df.captions.apply(lambda x:eval(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c8a14c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T00:16:40.975750Z",
     "start_time": "2025-08-24T00:16:40.955374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     image_id         file_name  \\\n",
       " 165     42888  000000042888.jpg   \n",
       " 33     532493  000000532493.jpg   \n",
       " 15     153299  000000153299.jpg   \n",
       " 312    284623  000000284623.jpg   \n",
       " 57     329319  000000329319.jpg   \n",
       " ..        ...               ...   \n",
       " 71     492282  000000492282.jpg   \n",
       " 106      2153  000000002153.jpg   \n",
       " 270    364297  000000364297.jpg   \n",
       " 348      6894  000000006894.jpg   \n",
       " 102    455219  000000455219.jpg   \n",
       " \n",
       "                                               captions  label  \n",
       " 165  A corner street sign with a tow sign and a art...      0  \n",
       " 33      A surfer on a white board riding a small wave.      0  \n",
       " 15   two giraffes are standing together outside a barn      0  \n",
       " 312               A black cat sits in a bathroom sink.      1  \n",
       " 57   A black and white cat sitting on top of a wood...      1  \n",
       " ..                                                 ...    ...  \n",
       " 71    A man who is riding a horse down a brick street.      0  \n",
       " 106  Batter preparing to swing at pitch during majo...      0  \n",
       " 270          There is a cat laying down on a keyboard.      1  \n",
       " 348  A man getting a kiss on the neck from an eleph...      0  \n",
       " 102  Some people in a field working with some big a...      0  \n",
       " \n",
       " [368 rows x 4 columns],\n",
       " label\n",
       " 0    184\n",
       " 1    184\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df, cat_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aac645",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T00:23:09.171716Z",
     "start_time": "2025-08-24T00:23:08.861870Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os, io, concurrent.futures\n",
    "# import pandas as pd\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "# from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "\n",
    "\n",
    "# def vision_feats_from_bytes(byte_list):\n",
    "#     imgs = [Image.open(io.BytesIO(b)).convert(\"RGB\") for b in byte_list]\n",
    "#     batch = processor(images=imgs, return_tensors=\"pt\")\n",
    "#     batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         vout = model.vision_tower(\n",
    "#             pixel_values=batch[\"pixel_values\"],\n",
    "#             output_hidden_states=True, return_dict=True\n",
    "#         )\n",
    "\n",
    "#     # Choose a layer/aggregation for your probe:\n",
    "#     # - CLS token if the encoder has one (often index 0)\n",
    "#     # - Mean pool over patch tokens\n",
    "#     # Many people use the penultimate layer for probes:\n",
    "#     last_hidden = vout.hidden_states[-2]   # (B, N_tokens, D)\n",
    "#     # If there is a CLS token: feats = last_hidden[:, 0]\n",
    "#     feats = last_hidden.mean(dim=1)        # mean pool over tokens -> (B, D)\n",
    "#     return feats  # detach if you like: feats.detach()\n",
    "\n",
    "# def _read_bytes(path: str) -> bytes:\n",
    "#     with open(path, \"rb\") as f:\n",
    "#         return f.read()\n",
    "\n",
    "# def preload_image_bytes(df: pd.DataFrame, root: str, max_workers: int = 8) -> dict:\n",
    "#     paths = [os.path.join(root, fn) for fn in df[\"file_name\"]]\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "#         data = list(ex.map(_read_bytes, paths))\n",
    "#     # map by file_name (or image_id if you prefer)\n",
    "#     return dict(zip(df[\"file_name\"], data))\n",
    "\n",
    "# data_name = 'cat'\n",
    "# ROOT = f\"../data/coco_val2017_{data_name}_binary_with_captions_balanced_images\"  # where 000000323303.jpg etc. live\n",
    "\n",
    "# # ---- load to RAM (compressed) ----\n",
    "# byte_cache = preload_image_bytes(cat_df, ROOT, max_workers=12)\n",
    "\n",
    "# # ---- PaliGemma setup ----\n",
    "# model_id = \"google/paligemma2-3b-pt-224\"\n",
    "# dtype = torch.float32\n",
    "# model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "#     model_id, torch_dtype=dtype, device_map=\"auto\"\n",
    "# )\n",
    "# model.vision_tower.config.output_hidden_states = True\n",
    "# processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# # ---- build a batch from in-RAM bytes and run forward/generate ----\n",
    "# def make_batch_from_bytes(filenames, prompts):\n",
    "#     imgs = [Image.open(io.BytesIO(byte_cache[fn])).convert(\"RGB\") for fn in filenames]\n",
    "#     # Processor handles resizing/normalization\n",
    "#     inputs = processor(images=imgs, text=prompts, return_tensors=\"pt\", padding=True)\n",
    "#     return {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "# # Example: yes/no “cat” probe for a subset\n",
    "# filenames = cat_df[\"file_name\"].head(16).tolist()\n",
    "# prompts = [\"Is there a cat in this image? Answer yes or no.\"] * len(filenames)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     batch = make_batch_from_bytes(filenames, prompts)\n",
    "#     out = model.generate(**batch, max_new_tokens=5)\n",
    "\n",
    "# preds = processor.batch_decode(out, skip_special_tokens=True)\n",
    "# print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de78d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41402ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:10:11.941406Z",
     "start_time": "2025-08-23T01:10:11.933454Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_df.captions.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3975eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:10:11.946331Z",
     "start_time": "2025-08-23T01:10:11.942911Z"
    }
   },
   "outputs": [],
   "source": [
    "texts_list, labels_list, filenames_list = [], [], [] # We don;t save imgs deitecely in RAM since that's not efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12472d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:10:11.954192Z",
     "start_time": "2025-08-23T01:10:11.947901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of cat_texts: 368, length of cat_labels: 368\n",
      "length of cat_texts: 368, length of cat_labels: 368\n",
      "length of human_texts: 1000, length of human_labels: 1000\n"
     ]
    }
   ],
   "source": [
    "cat_texts, cat_labels, cat_filenames = cat_df.captions.tolist(), cat_df.label.tolist(), cat_df.file_name.tolist()\n",
    "texts_list.append(cat_texts), labels_list.append(cat_labels), filenames_list.append(cat_filenames)\n",
    "print(f\"length of cat_texts: {len(cat_texts)}, length of cat_labels: {len(cat_labels)}\")\n",
    "dog_texts, dog_labels, dog_filenames = dog_df.captions.tolist(), dog_df.label.tolist(), dog_df.file_name.tolist()\n",
    "texts_list.append(dog_texts), labels_list.append(dog_labels), filenames_list.append(dog_filenames)\n",
    "print(f\"length of cat_texts: {len(cat_texts)}, length of cat_labels: {len(cat_labels)}\")\n",
    "human_texts, human_labels, human_filenames = human_df.captions.tolist(), human_df.label.tolist(), human_df.file_name.tolist()\n",
    "texts_list.append(human_texts), labels_list.append(human_labels), filenames_list.append(human_filenames)\n",
    "print(f\"length of human_texts: {len(human_texts)}, length of human_labels: {len(human_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11308c6",
   "metadata": {},
   "source": [
    "# load model & get act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7558f64b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:10:11.966224Z",
     "start_time": "2025-08-23T01:10:11.956057Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_models_with_eval(model_name, device=\"cuda\"):\n",
    "    if \"paligemma\" in model_name.lower():\n",
    "        from transformers import PaliGemmaForConditionalGeneration\n",
    "        model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "            model_name, \n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float32,  # Use fp16 for memory efficiency\n",
    "            device_map=None  # We'll handle device placement manually\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        language_model = model.language_model\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name, \n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float32,\n",
    "            device_map=None\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        language_model = model\n",
    "            \n",
    "    language_model.eval()\n",
    "    return language_model\n",
    "\n",
    "def get_inputs_from_text(model_name, text, device):\n",
    "#     if \"pali\" not in model_name:\n",
    "#         tokenizer = AutoTokenizer.from_pretrained(\"google/paligemma2-3b-pt-224\", use_fast=True) # Let's use paligemma tokeniser to avoid BOS token (same as in SAEs)\n",
    "#     else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # FIXED: More robust tokenization with proper padding token handling\n",
    "    # Ensure we have a pad token\n",
    "\n",
    "    # Tokenize with safer parameters\n",
    "    inputs = tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_SEQ_LEN,\n",
    "        add_special_tokens=True  # Ensure special tokens are added properly\n",
    "    )\n",
    "    if tokenizer.bos_token_id is not None:\n",
    "        inputs[\"attention_mask\"][:, 0] *= (inputs[\"input_ids\"][:, 0] != tokenizer.bos_token_id).to(inputs[\"attention_mask\"].dtype)\n",
    "    # FIXED: Validate token IDs are within vocabulary range\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    input_ids = inputs['input_ids']\n",
    "\n",
    "    # Check for out-of-bounds token IDs\n",
    "    if torch.any(input_ids >= vocab_size) or torch.any(input_ids < 0):\n",
    "        print(f\"⚠️  Invalid token IDs detected. Max ID: {input_ids.max()}, Vocab size: {vocab_size}\")\n",
    "        # Clamp invalid IDs to valid range\n",
    "        input_ids = torch.clamp(input_ids, 0, vocab_size - 1)\n",
    "        inputs['input_ids'] = input_ids\n",
    "\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    return inputs\n",
    "    \n",
    "def get_acts(language_model, text, layer, model_name, DEVICE):\n",
    "    inputs = get_inputs_from_text(model_name, text, DEVICE)\n",
    "    if hasattr(language_model, 'model') and hasattr(language_model.model, 'layers'):\n",
    "        if layer < len(language_model.model.layers):\n",
    "            target_layer = language_model.model.layers[layer]\n",
    "        else:\n",
    "            print(f\"❌ Layer {layer} out of range. Model has {len(language_model.model.layers)} layers\")\n",
    "            return torch.randn(1, 64, 2304).to(DEVICE), 0.0\n",
    "        \n",
    "    activations = language_model(**inputs, output_hidden_states=True)['hidden_states']\n",
    "    return activations\n",
    "#     activations = None\n",
    "\n",
    "\n",
    "#     def activation_hook(module, inputs, output):\n",
    "#         nonlocal activations\n",
    "#         try:\n",
    "#             if isinstance(output, tuple):\n",
    "#                 activations = output[0].clone().detach()\n",
    "#             else:\n",
    "#                 activations = output.clone().detach()\n",
    "#         except Exception as e:\n",
    "#             print(f\"⚠️  Error in activation hook: {e}\")\n",
    "\n",
    "#     # FIXED: More robust layer identification\n",
    "#     target_layer = None\n",
    "#     try:\n",
    "#         if hasattr(language_model, 'model') and hasattr(language_model.model, 'layers'):\n",
    "#             if layer < len(language_model.model.layers):\n",
    "#                 target_layer = language_model.model.layers[layer]\n",
    "#             else:\n",
    "#                 print(f\"❌ Layer {layer} out of range. Model has {len(language_model.model.layers)} layers\")\n",
    "#                 return torch.randn(1, 64, 2304).to(DEVICE), 0.0\n",
    "#         elif hasattr(language_model, 'layers'):\n",
    "#             if layer < len(language_model.layers):\n",
    "#                 target_layer = language_model.layers[layer]\n",
    "#             else:\n",
    "#                 print(f\"❌ Layer {layer} out of range. Model has {len(language_model.layers)} layers\")\n",
    "#                 return torch.randn(1, 64, 2304).to(DEVICE), 0.0\n",
    "#         else:\n",
    "#             print(f\"❌ Could not find layers in model structure\")\n",
    "#             return torch.randn(1, 64, 2304).to(DEVICE), 0.0\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Error accessing layer {layer}: {e}\")\n",
    "#         return torch.randn(1, 64, 2304).to(DEVICE), 0.0\n",
    "\n",
    "#     if target_layer is None:\n",
    "#         print(f\"❌ Could not find layer {layer}\")\n",
    "#         return torch.randn(1, 64, 2304).to(DEVICE), 0.0\n",
    "\n",
    "#     hook = target_layer.register_forward_hook(activation_hook)\n",
    "\n",
    "#     # Forward pass to get activations\n",
    "#     with torch.no_grad():\n",
    "#         try:\n",
    "#             if \"paligemma\" in model_name.lower():\n",
    "#                 _ = language_model(**inputs)\n",
    "#             else:\n",
    "#                 _ = language_model(**inputs)\n",
    "#         except Exception as e:\n",
    "#             print(f\"⚠️  Error in activation extraction: {e}\")\n",
    "\n",
    "#     hook.remove()\n",
    "#     if activations is None:\n",
    "#         print(f\"⚠️  Failed to extract activations from layer {layer}\")\n",
    "#         # FIXED: Return appropriate tensor size based on model\n",
    "#         try:\n",
    "#             # Try to get the actual hidden size from the model config\n",
    "#             if hasattr(language_model, 'config') and hasattr(language_model.config, 'hidden_size'):\n",
    "#                 hidden_size = language_model.config.hidden_size\n",
    "#             else:\n",
    "#                 hidden_size = 2304  # fallback\n",
    "#             activations = torch.randn(1, 64, hidden_size).to(DEVICE)\n",
    "#         except:\n",
    "#             activations = torch.randn(1, 64, 2304).to(DEVICE)\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4643dc45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:10:13.536181Z",
     "start_time": "2025-08-23T01:10:11.967954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize experiment\n",
    "experiment = LinearProbingExperiment(concept=\"cat_dog_classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44eab17",
   "metadata": {},
   "source": [
    "# cosine_sim between probe acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20db8ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:11:47.887578Z",
     "start_time": "2025-08-23T01:10:13.538345Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 67.94it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (1000, 2304)\n",
      "PolyGemma test data: (1000, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (800, 2304), size of gemma_labels_train: 800\n",
      "size of polygemma_activations_test: (200, 2304), size of polygemma_labels_test: 200\n",
      "X_train_flat shape: (800, 2304)\n",
      "y_train shape: 800\n",
      "X_test_flat shape: (200, 2304)\n",
      "y_test shape: 200\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- imports ---\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# ----------------------------\n",
    "# Cosine between probe weights\n",
    "# ----------------------------\n",
    "def _cos(a, b, eps=1e-12):\n",
    "    a = np.asarray(a).ravel()\n",
    "    b = np.asarray(b).ravel()\n",
    "    na = np.linalg.norm(a); nb = np.linalg.norm(b)\n",
    "    if na < eps or nb < eps:\n",
    "        return np.nan\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "def _effective_W_and_classes(probe):\n",
    "    \"\"\"Normalize (W, classes) so rows align to class ids.\n",
    "    - Binary LR: returns a single row for the positive class only (classes_[-1]).\n",
    "    - Multiclass: one row per class.\n",
    "    - Fallback: if classes_ missing, use row indices.\n",
    "    \"\"\"\n",
    "    W = np.atleast_2d(probe.coef_)\n",
    "    classes = getattr(probe, \"classes_\", None)\n",
    "    if classes is None:\n",
    "        classes = np.arange(W.shape[0])\n",
    "\n",
    "    classes = np.asarray(classes)\n",
    "    if W.shape[0] == 1 and classes.shape[0] == 2:\n",
    "        # Binary LR: single direction corresponds to positive class (classes_[-1])\n",
    "        classes_eff = np.array([classes[-1]])\n",
    "        W_eff = W\n",
    "    else:\n",
    "        # Trim/align lengths conservatively\n",
    "        k = min(W.shape[0], classes.shape[0])\n",
    "        W_eff = W[:k]\n",
    "        classes_eff = classes[:k]\n",
    "    return W_eff, classes_eff\n",
    "\n",
    "def cosine_weights_by_class(probe_a, probe_b, ignore_sign=False):\n",
    "    W_a, classes_a = _effective_W_and_classes(probe_a)\n",
    "    W_b, classes_b = _effective_W_and_classes(probe_b)\n",
    "\n",
    "    # Align on common classes (works for binary and multiclass)\n",
    "    set_b = {c: i for i, c in enumerate(classes_b)}\n",
    "    common = [(i, set_b[c], c) for i, c in enumerate(classes_a) if c in set_b]\n",
    "\n",
    "    if not common:\n",
    "        # Last-resort fallback: cosine over flattened weights\n",
    "        val = _cos(W_a.ravel(), W_b.ravel())\n",
    "        return {\"_fallback\": abs(val) if ignore_sign else val}, (abs(val) if ignore_sign else val)\n",
    "\n",
    "    per_class = {}\n",
    "    for ia, ib, c in common:\n",
    "        val = _cos(W_a[ia], W_b[ib])\n",
    "        per_class[c] = abs(val) if ignore_sign else val\n",
    "\n",
    "    mean_val = float(np.nanmean(list(per_class.values())))\n",
    "    return per_class, mean_val\n",
    "\n",
    "# -----------------------------------------\n",
    "# New: precompute pooled activations (once)\n",
    "# -----------------------------------------\n",
    "def precompute_pooled_activations(\n",
    "    model, tokenizer, texts, layers, device,\n",
    "    batch_size=8, pool=\"mean\", max_length=256\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a dict: layer_index -> np.ndarray of shape (N, hidden_size)\n",
    "    Only stores pooled (sequence-reduced) representations per layer.\n",
    "    Memory friendly: processes in batches, moves results to CPU immediately.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    acts = {l: [] for l in layers}\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for start in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[start:start + batch_size]\n",
    "            enc = tokenizer(\n",
    "                batch_texts, return_tensors=\"pt\",\n",
    "                padding=True, truncation=True, max_length=max_length\n",
    "            )\n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "            # One forward produces ALL hidden states; we only keep pooled summaries.\n",
    "            outputs = model(**enc, output_hidden_states=True, return_dict=True)\n",
    "            hidden_states = outputs.hidden_states  # tuple len = num_layers+1\n",
    "            # hidden_states[i] shape: (B, T, D). Index 0 = embeddings, 1..L = layer outputs.\n",
    "\n",
    "            for l in layers:\n",
    "                hs = hidden_states[l]  # (B, T, D)\n",
    "                if pool == \"cls\":\n",
    "                    # If your model lacks a dedicated [CLS], prefer pool=\"mean\"\n",
    "                    pooled = hs[:, 0, :]                   # (B, D)\n",
    "                elif pool == \"last\":\n",
    "                    pooled = hs[torch.arange(hs.size(0)), (enc[\"attention_mask\"].sum(dim=1)-1).clamp(min=0), :]\n",
    "                else:\n",
    "                    # mean-pooled over tokens actually attended to\n",
    "                    mask = enc[\"attention_mask\"].unsqueeze(-1)  # (B, T, 1)\n",
    "                    summed = (hs * mask).sum(dim=1)             # (B, D)\n",
    "                    denom = mask.sum(dim=1).clamp(min=1)        # (B, 1)\n",
    "                    pooled = summed / denom                     # (B, D)\n",
    "\n",
    "                acts[l].append(pooled.detach().cpu().numpy())\n",
    "\n",
    "            # Cleanup this batch\n",
    "            del outputs, hidden_states, enc\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Concatenate batches along sample axis\n",
    "    acts = {l: np.concatenate(chunks, axis=0) for l, chunks in acts.items()}\n",
    "    return acts\n",
    "\n",
    "# ---------------------------------\n",
    "# Setup models/tokenizers once\n",
    "# ---------------------------------\n",
    "model1_name = \"google/gemma-2-2b\"\n",
    "model2_name = \"google/paligemma2-3b-pt-224\"\n",
    "\n",
    "model1 = load_models_with_eval(model1_name, DEVICE_1)  # Gemma (text)\n",
    "model2 = load_models_with_eval(model2_name, DEVICE_2)  # PaliGemma (text)\n",
    "\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(\"google/paligemma2-3b-pt-224\", use_fast=True) # Let's use paligemma tokeniser to avoid BOS token (same as in SAEs)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model2_name, use_fast=True) \n",
    "# Safeguard layer list: use the min num_layers across models\n",
    "L1 = getattr(model1.config, \"num_hidden_layers\", 26)\n",
    "L2 = getattr(model2.config, \"num_hidden_layers\", 26)\n",
    "layer_to_test = [l for l in range(1, min(L1, L2) + 1)]  # 1..min(L1,L2)\n",
    "\n",
    "# ---------------------------------\n",
    "# Main loop per concept/dataset\n",
    "# ---------------------------------\n",
    "data_name_list = ['cat', 'dog', 'human']\n",
    "out_root = \"../figs_tabs\"\n",
    "\n",
    "for texts, labels, data_name in zip(texts_list, labels_list, data_name_list):\n",
    "\n",
    "    # 1) Precompute per-layer pooled activations ONCE per model (CPU cache)\n",
    "    acts1 = precompute_pooled_activations(\n",
    "        model1, tokenizer1, texts, layer_to_test, DEVICE_1,\n",
    "        batch_size=8, pool=\"mean\", max_length=256\n",
    "    )\n",
    "    acts2 = precompute_pooled_activations(\n",
    "        model2, tokenizer2, texts, layer_to_test, DEVICE_2,\n",
    "        batch_size=8, pool=\"mean\", max_length=256\n",
    "    )\n",
    "\n",
    "    # 2) Train probes per layer using cached activations; compute cosines\n",
    "    cos_signed, cos_abs = [], []\n",
    "\n",
    "    for layer in layer_to_test:\n",
    "        model1_activations = acts1[layer]   # shape (N, D1)\n",
    "        model2_activations = acts2[layer]   # shape (N, D2)\n",
    "\n",
    "        # Train probes — keep your existing experiment API\n",
    "        sklearn_probe_1, _ = experiment.run_experiment(\n",
    "            model1_activations, labels,\n",
    "            model2_activations, labels\n",
    "        )\n",
    "        sklearn_probe_2, _ = experiment.run_experiment(\n",
    "            model2_activations, labels,\n",
    "            model1_activations, labels\n",
    "        )\n",
    "\n",
    "        # Cosine between probe weight vectors (concept directions)\n",
    "        _, cos_signed_mean = cosine_weights_by_class(\n",
    "            sklearn_probe_1, sklearn_probe_2, ignore_sign=False\n",
    "        )\n",
    "        _, cos_abs_mean = cosine_weights_by_class(\n",
    "            sklearn_probe_1, sklearn_probe_2, ignore_sign=True\n",
    "        )\n",
    "\n",
    "        cos_signed.append(cos_signed_mean)\n",
    "        cos_abs.append(cos_abs_mean)\n",
    "\n",
    "    # 3) Plot & save for this concept\n",
    "    out_dir = os.path.join(out_root, data_name)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(layer_to_test, cos_signed, label=\"signed cosine\")\n",
    "    plt.title(f\"Gemma vs Pali probe-weight similarity by layer — {data_name}\")\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"Cosine similarity\")\n",
    "    plt.ylim(-1.05, 1.05)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f\"{data_name}_probe_weight_cosine.png\"), dpi=200)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # 4) Cleanup caches for this concept\n",
    "    del acts1, acts2\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529f1bb5",
   "metadata": {},
   "source": [
    "# All probe exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b618c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:11:47.899182Z",
     "start_time": "2025-08-23T01:11:47.889683Z"
    }
   },
   "outputs": [],
   "source": [
    "import json, numpy as np, torch\n",
    "from contextlib import suppress\n",
    "\n",
    "DROP_KEYS = {\n",
    "    \"model\", \"estimator\", \"clf\", \"classifier\", \"pipeline\",\n",
    "    \"sklearn_probe\", \"probe\", \"vectorizer\", \"scaler\", \"pca\",\n",
    "    \"figure\", \"fig\", \"axes\", \"ax\", \"roc_curve_fig\", \"pr_curve_fig\"\n",
    "}\n",
    "\n",
    "def json_sanitize(obj, _visited=None):\n",
    "    if _visited is None: _visited = set()\n",
    "    oid = id(obj)\n",
    "    if oid in _visited:\n",
    "        return \"<circular_ref>\"\n",
    "    _visited.add(oid)\n",
    "\n",
    "    # Primitives\n",
    "    if obj is None or isinstance(obj, (bool, int, float, str)):\n",
    "        return obj\n",
    "\n",
    "    # NumPy / torch\n",
    "    if isinstance(obj, (np.integer, np.floating)):\n",
    "        return obj.item()\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.detach().cpu().tolist()\n",
    "\n",
    "    # Mappings\n",
    "    if isinstance(obj, dict):\n",
    "        out = {}\n",
    "        for k, v in obj.items():\n",
    "            k_str = str(k)\n",
    "            if k_str in DROP_KEYS:\n",
    "                continue\n",
    "            out[k_str] = json_sanitize(v, _visited)\n",
    "        return out\n",
    "\n",
    "    # Sequences / Sets / Tuples\n",
    "    if isinstance(obj, (list, tuple, set)):\n",
    "        return [json_sanitize(v, _visited) for v in obj]\n",
    "\n",
    "    # sklearn classification_report (string ok), others: use repr as last resort\n",
    "    with suppress(Exception):\n",
    "        return repr(obj)\n",
    "    return str(obj)\n",
    "\n",
    "def safe_save_results(results, path, meta=None):\n",
    "    minimal = {\n",
    "        \"meta\": meta or {},\n",
    "        \"sklearn\": {\n",
    "            \"train_acc\": float(results[\"sklearn\"].get(\"train_acc\", float(\"nan\"))),\n",
    "            \"test_acc\":  float(results[\"sklearn\"].get(\"test_acc\",  float(\"nan\"))),\n",
    "            # keep dict report if available; if it’s a string it’s also fine\n",
    "            \"classification_report\": results[\"sklearn\"].get(\"classification_report\", None),\n",
    "            \"y_test\": [int(x) for x in results[\"sklearn\"].get(\"y_test\", [])],\n",
    "            \"y_pred\": [int(x) for x in results[\"sklearn\"].get(\"y_pred\", [])],\n",
    "        }\n",
    "    }\n",
    "    # merge any extra *safe* fields\n",
    "    sanitized = json_sanitize(results)\n",
    "    minimal[\"extra\"] = sanitized.get(\"extra\", {})  # optional\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(minimal, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5590d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:22:11.397500Z",
     "start_time": "2025-08-23T01:18:25.181909Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, gc, io, json\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# -----------------------------\n",
    "# Precompute pooled activations\n",
    "# ----------------------------\n",
    "\n",
    "def _amp_ctx(device, use_amp=True):\n",
    "    \"\"\"Return a context manager for autocast if on CUDA, else a no-op.\"\"\"\n",
    "    if not use_amp:\n",
    "        return nullcontext()\n",
    "    is_cuda = torch.cuda.is_available() and (\n",
    "        str(device).startswith(\"cuda\") or getattr(getattr(device, \"type\", None), \"__str__\", lambda: \"\")() == \"cuda\"\n",
    "        or (hasattr(device, \"type\") and device.type == \"cuda\")\n",
    "    )\n",
    "    if not is_cuda:\n",
    "        return nullcontext()\n",
    "    # Prefer new API if available\n",
    "    try:\n",
    "        return torch.autocast(\"cuda\", dtype=torch.float16)\n",
    "    except Exception:\n",
    "        # Fallback for older PyTorch\n",
    "        return torch.cuda.amp.autocast(dtype=torch.float16)\n",
    "\n",
    "    \n",
    "def precompute_pooled_activations(\n",
    "    model, tokenizer, texts, layers, device,\n",
    "    batch_size=8, pool=\"mean\", max_length=256, use_amp=True\n",
    "):\n",
    "    model.eval()\n",
    "    acts = {l: [] for l in layers}\n",
    "\n",
    "    with torch.inference_mode(), _amp_ctx(device, use_amp):\n",
    "        for start in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[start:start+batch_size]\n",
    "            enc = tokenizer(\n",
    "                batch_texts, return_tensors=\"pt\",\n",
    "                padding=True, truncation=True, max_length=max_length\n",
    "            )\n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "            out = model(**enc, output_hidden_states=True, return_dict=True)\n",
    "            hs_tuple = out.hidden_states  # (emb, layer1, ..., layerL)\n",
    "\n",
    "            mask = enc[\"attention_mask\"].unsqueeze(-1)  # (B,T,1)\n",
    "            for l in layers:\n",
    "                hs = hs_tuple[l]  # (B,T,D)\n",
    "                if pool == \"cls\":\n",
    "                    pooled = hs[:, 0, :]\n",
    "                elif pool == \"last\":\n",
    "                    last_idx = (enc[\"attention_mask\"].sum(dim=1)-1).clamp(min=0)\n",
    "                    pooled = hs[torch.arange(hs.size(0), device=hs.device), last_idx, :]\n",
    "                else:  # mean\n",
    "                    summed = (hs * mask).sum(dim=1)\n",
    "                    denom  = mask.sum(dim=1).clamp(min=1)\n",
    "                    pooled = summed / denom\n",
    "\n",
    "                acts[l].append(pooled.detach().cpu().numpy())\n",
    "\n",
    "            del out, hs_tuple, enc\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    acts = {l: np.concatenate(chunks, axis=0) for l, chunks in acts.items()}\n",
    "    return acts\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Utility: load -> precompute -> unload\n",
    "# -----------------------------------------\n",
    "def compute_acts_for_model_name(model_name, texts, layers, device):\n",
    "    model = load_models_with_eval(model_name, device)\n",
    "    if \"pali\" not in model_name:\n",
    "        tok = AutoTokenizer.from_pretrained(\"google/paligemma2-3b-pt-224\", use_fast=True)\n",
    "    else:\n",
    "        tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    acts = precompute_pooled_activations(model, tok, texts, layers, device)\n",
    "    # derive feature dim for sanity checks\n",
    "    any_layer = layers[0]\n",
    "    feat_dim = acts[any_layer].shape[1]\n",
    "    # free VRAM\n",
    "    del model, tok\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return acts, feat_dim\n",
    "\n",
    "# -----------------------------------------\n",
    "# MAIN\n",
    "# -----------------------------------------\n",
    "model1_names = [\"google/gemma-2-2b\", \"google/paligemma2-3b-pt-224\"]\n",
    "model2_names = [\"google/gemma-2-2b\", \"google/paligemma2-3b-pt-224\"]\n",
    "data_name_list = ['cat', 'dog', 'human']\n",
    "\n",
    "# Decide layers safely (take min across all models)\n",
    "# (We’ll pull num_hidden_layers from the first time each model is loaded.)\n",
    "# To avoid loading twice, we’ll compute activations right away per model.\n",
    "for texts, labels, data_name in zip(texts_list, labels_list, data_name_list):\n",
    "    print(f\"\\n=== Precomputing activations for concept: {data_name} ===\", flush=True)\n",
    "\n",
    "    # Figure out which models we need for this concept\n",
    "    needed_models = sorted(set(model1_names + model2_names))\n",
    "\n",
    "    # Decide a shared layer list AFTER we’ve inspected all model configs\n",
    "    # Strategy: compute acts per model one-by-one, track each model's L and cache acts.\n",
    "    acts_cache = {}\n",
    "    feat_dims  = {}\n",
    "    max_layers_by_model = {}\n",
    "\n",
    "    # We’ll read num_hidden_layers from config after loading; then save acts & unload model.\n",
    "    for mname in needed_models:\n",
    "        # Load once, grab num layers, compute acts, unload\n",
    "        tmp_model = load_models_with_eval(mname, DEVICE_1)\n",
    "        num_layers = int(getattr(tmp_model.config, \"num_hidden_layers\", 26))\n",
    "        del tmp_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        max_layers_by_model[mname] = num_layers\n",
    "\n",
    "    # shared 1..L across all models\n",
    "    layer_to_test = list(range(1, min(max_layers_by_model.values()) + 1))\n",
    "\n",
    "    # Now compute & cache acts per model (sequentially to save memory)\n",
    "    for mname in needed_models:\n",
    "        print(f\"  -> computing acts for {mname} (layers {layer_to_test[0]}..{layer_to_test[-1]})\", flush=True)\n",
    "        acts_cache[mname], feat_dims[mname] = compute_acts_for_model_name(\n",
    "            mname, texts, layer_to_test, DEVICE_1\n",
    "        )\n",
    "\n",
    "    # Cross-model experiments\n",
    "    for model1_name in model1_names:\n",
    "        for model2_name in model2_names:\n",
    "            print(f\"\\nRunning linear probing experiment: {data_name} | train on {model1_name.split('/')[-1]} → test on {model2_name.split('/')[-1]}\", flush=True)\n",
    "\n",
    "            all_results = []\n",
    "            train_accs, test_accs = [], []\n",
    "\n",
    "            # Optional: if feature dims mismatch, reduce both to the shared min-dim via PCA\n",
    "            d1, d2 = feat_dims[model1_name], feat_dims[model2_name]\n",
    "            shared_d = min(d1, d2)\n",
    "            use_pca = (d1 != d2)\n",
    "\n",
    "            if use_pca:\n",
    "                from sklearn.decomposition import PCA\n",
    "\n",
    "            for layer in layer_to_test:\n",
    "                X_train = acts_cache[model1_name][layer]  # (N, d1)\n",
    "                X_test  = acts_cache[model2_name][layer]  # (N, d2)\n",
    "\n",
    "                if use_pca:\n",
    "                    # Fit PCA on TRAIN only, transform both to shared_d\n",
    "                    pca = PCA(n_components=shared_d, svd_solver=\"auto\", random_state=0)\n",
    "                    X_train_reduced = pca.fit_transform(X_train)\n",
    "                    X_test_reduced  = pca.transform(X_test)\n",
    "                else:\n",
    "                    X_train_reduced, X_test_reduced = X_train, X_test\n",
    "\n",
    "                # === Run probe experiment ===\n",
    "                # Suppress inner prints if run_experiment is verbose\n",
    "                with redirect_stdout(io.StringIO()):\n",
    "                    results = experiment.run_experiment(\n",
    "                        X_train_reduced, labels,\n",
    "                        X_test_reduced,  labels\n",
    "                    )\n",
    "\n",
    "                all_results.append(results)\n",
    "\n",
    "                # Console summary\n",
    "                tr = results[1]['sklearn']['train_acc']\n",
    "                te = results[1]['sklearn']['test_acc']\n",
    "                train_accs.append(tr); test_accs.append(te)\n",
    "                print(f\"[layer {layer:02d}] train_acc={tr:.4f} | test_acc={te:.4f}\")\n",
    "\n",
    "                # Save per-layer JSON\n",
    "                os.makedirs(f\"../output/{data_name}\", exist_ok=True)\n",
    "                tag = f\"{model1_name.split('/')[-1]}_{model2_name.split('/')[-1]}\"\n",
    "                save_path = f\"../output/{data_name}/linear_probing_results_{layer}_{tag}.json\"\n",
    "                meta = {\"data\": data_name, \"layer\": layer,\n",
    "                        \"train_model\": model1_name, \"test_model\": model2_name}\n",
    "                try:\n",
    "                    safe_save_results(results, save_path, meta=meta)\n",
    "                except Exception as e:\n",
    "                    print(f\"(warn) safe_save_results failed: {e}. Writing ultra-minimal JSON.\")\n",
    "                    ultra = {\n",
    "                        \"meta\": meta,\n",
    "                        \"train_acc\": float(results[1][\"sklearn\"][\"train_acc\"]),\n",
    "                        \"test_acc\":  float(results[1][\"sklearn\"][\"test_acc\"])\n",
    "                    }\n",
    "                    with open(save_path.replace(\".json\", \"_minimal.json\"), \"w\") as f:\n",
    "                        json.dump(ultra, f, indent=2)\n",
    "\n",
    "\n",
    "                # free per-iteration temps\n",
    "                del X_train_reduced, X_test_reduced, results\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # ===== Plot Train and Test Accuracy Across Layers =====\n",
    "            layers = layer_to_test\n",
    "            plt.figure(figsize=(7, 4))\n",
    "            plt.plot(layers, train_accs, label='Train')\n",
    "            plt.plot(layers, test_accs,  label='Test', linestyle=\"--\")\n",
    "            plt.xlabel('Layer'); plt.ylabel('Accuracy')\n",
    "            plt.title(f\"{data_name} — Train/Test accuracy by layer\\ntrain={model1_name.split('/')[-1]} → test={model2_name.split('/')[-1]}\")\n",
    "            plt.ylim(0.0, 1.0); plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout()\n",
    "            os.makedirs(f\"../figs_tabs/{data_name}/\", exist_ok=True)\n",
    "            plt.savefig(f\"../figs_tabs/{data_name}/acc_by_layer_{model1_name.split('/')[-1]}_{model2_name.split('/')[-1]}.png\", dpi=200)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    # Clear cached activations for this concept to free RAM\n",
    "    del acts_cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea599a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T01:12:25.161366Z",
     "start_time": "2025-08-23T01:12:25.161358Z"
    }
   },
   "outputs": [],
   "source": [
    "# load models\n",
    "model1_names = [\"google/gemma-2-2b\", \"google/paligemma2-3b-pt-224\"]\n",
    "model2_names = [\"google/gemma-2-2b\", \"google/paligemma2-3b-pt-224\"]\n",
    "data_name_list = ['cat', 'dog', 'human']\n",
    "for texts, labels, data_name in zip(texts_list, labels_list, data_name_list):\n",
    "    for model1_name in model1_names:\n",
    "        for model2_name in model2_names:\n",
    "\n",
    "            model1 = load_models_with_eval(model1_name, DEVICE_1)\n",
    "            model2 = load_models_with_eval(model2_name, DEVICE_2)\n",
    "\n",
    "            # # Dummy activations (replace with real data)\n",
    "            # gemma_activations = np.random.randn(1000, 768)  # 1000 samples, 768 dims\n",
    "            # gemma_labels = np.random.randint(0, 2, 1000)    # binary cat/dog labels\n",
    "\n",
    "            # polygemma_activations = np.random.randn(200, 768)  # 200 test samples\n",
    "            # polygemma_labels = np.random.randint(0, 2, 200)\n",
    "\n",
    "            layer_to_test = list(range(1, 27))\n",
    "            all_results = []\n",
    "            # Run experiment per layer\n",
    "            for layer in layer_to_test:\n",
    "                # Produce activation-label pairs\n",
    "                with torch.inference_mode():\n",
    "                    model1_activations = get_acts(model1, texts, layer, model1_name, DEVICE_1)\n",
    "                    model2_activations = get_acts(model2, texts, layer, model2_name, DEVICE_2)\n",
    "\n",
    "                # === Run probe experiment ===\n",
    "                results = experiment.run_experiment(\n",
    "                    model1_activations, labels,\n",
    "                    model2_activations, labels\n",
    "                )\n",
    "    \n",
    "                all_results.append(results)\n",
    "\n",
    "                print(f\"\\n=== LAYER {layer} RESULTS ===\")\n",
    "                print(f\"Train Accuracy: {results['sklearn']['train_acc']:.4f}\")\n",
    "                print(f\"Test Accuracy: {results['sklearn']['test_acc']:.4f}\")\n",
    "                print(\"Classification Report:\")\n",
    "                print(results['sklearn']['classification_report'])\n",
    "                      \n",
    "                 \n",
    "                      \n",
    "                # Save results\n",
    "                os.makedirs(f\"../output/{data_name}\", exist_ok=True)\n",
    "                experiment.save_results(results, f\"../output/{data_name}/linear_probing_results_{layer}_{model1_name.split('/')[-1]}_{model2_name.split('/')[-1]}.json\")\n",
    "\n",
    "                # Save misclassified examples\n",
    "                if 'y_test' in results['sklearn'] and 'y_pred' in results['sklearn']:\n",
    "                    mis_indices = [i for i, (yt, yp) in enumerate(zip(\n",
    "                        results['sklearn']['y_test'], results['sklearn']['y_pred']\n",
    "                    )) if yt != yp]\n",
    "                    mis_info = [\n",
    "                        {\n",
    "                            'text': cat_texts[i],  # assuming you meant cat_texts not text\n",
    "                            'true_label': int(results['sklearn']['y_test'][i]),\n",
    "                            'pred_label': int(results['sklearn']['y_pred'][i])\n",
    "                        }\n",
    "                        for i in mis_indices\n",
    "                    ]\n",
    "                    os.makedirs(f\"../output/{data_name}/{model1_name.split('/')[-1]}_{model2_name.split('/')[-1]}\", exist_ok=True)\n",
    "                    with open(f\"../output/{data_name}/{model1_name.split('/')[-1]}_{model2_name.split('/')[-1]}/misclassified_layer_{layer}.json\", 'w') as f:\n",
    "                        json.dump(mis_info, f, indent=2)\n",
    "                else:\n",
    "                    print(\"Warning: 'y_test' or 'y_pred' not found in results; misclassifications not saved.\")\n",
    "\n",
    "                del model1_activations, model2_activations, results\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # ===== Plot Train and Test Accuracy Across Layers =====\n",
    "\n",
    "            layers = layer_to_test\n",
    "            train_accs = [res['sklearn']['train_acc'] for res in all_results]\n",
    "            test_accs = [res['sklearn']['test_acc'] for res in all_results]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(layers, train_accs)\n",
    "            plt.plot(layers, test_accs)\n",
    "            plt.xlabel('Layer')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f\"Train and Test Accuracy by Layer_{model1_name.split('/')[-1]}_{model2_name.split('/')[-1]}. Concept: {data_name}\")\n",
    "            plt.legend(['Train', 'Test'])\n",
    "            os.makedirs(f\"../figs_tabs/{data_name}/\", exist_ok=True)\n",
    "            plt.savefig(f\"../figs_tabs/{data_name}/Linear Probe Train and Test Accuracy by Layer_{model1_name.split('/')[-1]}_{model2_name.split('/')[-1]}.png\")\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc2900",
   "metadata": {},
   "source": [
    "# All exps (image to pali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8246cc54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'needed_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m acts, feat_dim\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Figure out max layers per model (decoder for Gemma, VISION for PaliGemma)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mname \u001b[38;5;129;01min\u001b[39;00m needed_models:\n\u001b[32m     64\u001b[39m     tmp_model = load_models_with_eval(mname, DEVICE_1)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpali\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mname.lower():\n",
      "\u001b[31mNameError\u001b[39m: name 'needed_models' is not defined"
     ]
    }
   ],
   "source": [
    "# # NEW imports (top of file)\n",
    "# from contextlib import nullcontext\n",
    "# from PIL import Image\n",
    "# from transformers import AutoProcessor\n",
    "# import concurrent.futures\n",
    "\n",
    "# # NEW: preload compressed image bytes into RAM once per dataset\n",
    "# def _read_bytes(path: str) -> bytes:\n",
    "#     with open(path, \"rb\") as f:\n",
    "#         return f.read()\n",
    "\n",
    "# def preload_image_bytes(filenames, root, max_workers: int = 12):\n",
    "#     paths = [os.path.join(root, fn) for fn in filenames]\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "#         data = list(ex.map(_read_bytes, paths))\n",
    "#     return dict(zip(filenames, data))\n",
    "# # NEW imports (top of file)\n",
    "# from contextlib import nullcontext\n",
    "# from PIL import Image\n",
    "# from transformers import AutoProcessor\n",
    "# import concurrent.futures\n",
    "\n",
    "# # NEW: preload compressed image bytes into RAM once per dataset\n",
    "# def _read_bytes(path: str) -> bytes:\n",
    "#     with open(path, \"rb\") as f:\n",
    "#         return f.read()\n",
    "\n",
    "# def preload_image_bytes(filenames, root, max_workers: int = 12):\n",
    "#     paths = [os.path.join(root, fn) for fn in filenames]\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "#         data = list(ex.map(_read_bytes, paths))\n",
    "#     return dict(zip(filenames, data))\n",
    "\n",
    "# def compute_acts_for_model_name(\n",
    "#     model_name, texts, layers, device,\n",
    "#     img_filenames=None, img_byte_cache=None, pool=\"mean\"\n",
    "# ):\n",
    "#     model = load_models_with_eval(model_name, device)\n",
    "\n",
    "#     if \"pali\" in model_name.lower():\n",
    "#         preproc = AutoProcessor.from_pretrained(model_name)\n",
    "#         acts = precompute_pooled_activations(\n",
    "#             model, preproc, texts, layers, device,\n",
    "#             pool=pool, is_pali=True,\n",
    "#             img_filenames=img_filenames, img_byte_cache=img_byte_cache\n",
    "#         )\n",
    "#         any_layer = layers[0]; feat_dim = acts[any_layer].shape[1]\n",
    "#         del model, preproc\n",
    "#     else:\n",
    "#         tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "#         acts = precompute_pooled_activations(\n",
    "#             model, tok, texts, layers, device, pool=pool\n",
    "#         )\n",
    "#         any_layer = layers[0]; feat_dim = acts[any_layer].shape[1]\n",
    "#         del model, tok\n",
    "\n",
    "#     gc.collect(); torch.cuda.empty_cache()\n",
    "#     return acts, feat_dim\n",
    "\n",
    "\n",
    "\n",
    "# # Figure out max layers per model (decoder for Gemma, VISION for PaliGemma)\n",
    "# for mname in needed_models:\n",
    "#     tmp_model = load_models_with_eval(mname, DEVICE_1)\n",
    "#     if \"pali\" in mname.lower():\n",
    "#         num_layers = int(getattr(tmp_model.vision_tower.config, \"num_hidden_layers\",\n",
    "#                           getattr(tmp_model.vision_tower.config, \"num_layers\", 24)))\n",
    "#     else:\n",
    "#         num_layers = int(getattr(tmp_model.config, \"num_hidden_layers\", 26))\n",
    "#     del tmp_model\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "#     max_layers_by_model[mname] = num_layers\n",
    "\n",
    "# layer_to_test = list(range(1, min(max_layers_by_model.values()) + 1))\n",
    "\n",
    "# IMG_ROOT =  f\"../data/coco_val2017_{data_name}_binary_with_captions_balanced_images\" \n",
    "\n",
    "# for texts, labels, data_name, filenames in zip(texts_list, labels_list, data_name_list, filenames_list):\n",
    "#     print(f\"\\n=== Precomputing activations for concept: {data_name} ===\", flush=True)\n",
    "\n",
    "#     # Build one byte cache per dataset (reused across models)\n",
    "#     img_byte_cache = preload_image_bytes(filenames, IMG_ROOT, max_workers=12)\n",
    "\n",
    "#     needed_models = sorted(set(model1_names + model2_names))\n",
    "#     acts_cache = {}\n",
    "#     feat_dims  = {}\n",
    "#     max_layers_by_model = {}\n",
    "\n",
    "#     # (layer discovery block from Section 4 here)\n",
    "\n",
    "#     # Now compute & cache acts per model\n",
    "#     for mname in needed_models:\n",
    "#         print(f\"  -> computing acts for {mname} (layers {layer_to_test[0]}..{layer_to_test[-1]})\", flush=True)\n",
    "#         if \"pali\" in mname.lower():\n",
    "#             acts_cache[mname], feat_dims[mname] = compute_acts_for_model_name(\n",
    "#                 mname, texts=None, layers=layer_to_test, device=DEVICE_1,\n",
    "#                 img_filenames=filenames, img_byte_cache=img_byte_cache, pool=\"mean\"\n",
    "#             )\n",
    "#         else:\n",
    "#             acts_cache[mname], feat_dims[mname] = compute_acts_for_model_name(\n",
    "#                 mname, texts=texts, layers=layer_to_test, device=DEVICE_1, pool=\"mean\"\n",
    "#             )\n",
    "\n",
    "#     # ... the rest of your cross-model experiment loop stays unchanged ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af8866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Concept: cat ===\n",
      "\n",
      "Running linear probe: cat | train on gemma-2-2b → test on gemma-2-2b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 53.51it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 57.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 01 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 02 | train_acc=1.0000 | test_acc=0.9730\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 03 | train_acc=1.0000 | test_acc=0.9730\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 04 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 05 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 06 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 07 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 08 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 09 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 10 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 11 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 12 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 13 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 14 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 15 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 16 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 17 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 18 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 19 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 20 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 21 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 22 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 23 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 24 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 25 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 26 | train_acc=1.0000 | test_acc=0.9459\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running linear probe: cat | train on gemma-2-2b → test on paligemma2-3b-pt-224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 57.34it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 01 | train_acc=1.0000 | test_acc=0.9730\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 02 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 03 | train_acc=1.0000 | test_acc=0.9595\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 04 | train_acc=1.0000 | test_acc=0.9054\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 05 | train_acc=1.0000 | test_acc=0.9189\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 06 | train_acc=1.0000 | test_acc=0.8919\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 07 | train_acc=1.0000 | test_acc=0.9054\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 08 | train_acc=1.0000 | test_acc=0.7703\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 09 | train_acc=1.0000 | test_acc=0.8243\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 10 | train_acc=1.0000 | test_acc=0.8243\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 11 | train_acc=1.0000 | test_acc=0.8514\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 12 | train_acc=1.0000 | test_acc=0.7568\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 13 | train_acc=1.0000 | test_acc=0.8243\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 14 | train_acc=1.0000 | test_acc=0.6351\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 15 | train_acc=1.0000 | test_acc=0.6892\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 16 | train_acc=1.0000 | test_acc=0.5946\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 17 | train_acc=1.0000 | test_acc=0.6486\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 18 | train_acc=1.0000 | test_acc=0.6622\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 19 | train_acc=1.0000 | test_acc=0.5946\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 20 | train_acc=1.0000 | test_acc=0.6486\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 21 | train_acc=1.0000 | test_acc=0.8108\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n",
      "Running linear probing experiment: cat_dog_classification\n",
      "Gemma training data: (368, 2304)\n",
      "PolyGemma test data: (368, 2304)\n",
      "\n",
      "--- Training sklearn probe ---\n",
      "size of gemma_activations_train: (294, 2304), size of gemma_labels_train: 294\n",
      "size of polygemma_activations_test: (74, 2304), size of polygemma_labels_test: 74\n",
      "X_train_flat shape: (294, 2304)\n",
      "y_train shape: 294\n",
      "X_test_flat shape: (74, 2304)\n",
      "y_test shape: 74\n",
      "[cat] layer 22 | train_acc=1.0000 | test_acc=0.6622\n",
      "(warn) save_results failed (Circular reference detected); writing minimal JSON.\n"
     ]
    }
   ],
   "source": [
    "# ========= helpers for this loop =========\n",
    "from contextlib import nullcontext\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoProcessor\n",
    "import concurrent.futures\n",
    "def _amp_ctx(device, use_amp=True):\n",
    "    \"\"\"Return a context manager for autocast if on CUDA, else a no-op.\"\"\"\n",
    "    if not use_amp:\n",
    "        return nullcontext()\n",
    "    is_cuda = torch.cuda.is_available() and (\n",
    "        str(device).startswith(\"cuda\") or getattr(getattr(device, \"type\", None), \"__str__\", lambda: \"\")() == \"cuda\"\n",
    "        or (hasattr(device, \"type\") and device.type == \"cuda\")\n",
    "    )\n",
    "    if not is_cuda:\n",
    "        return nullcontext()\n",
    "    # Prefer new API if available\n",
    "    try:\n",
    "        return torch.autocast(\"cuda\", dtype=torch.float16)\n",
    "    except Exception:\n",
    "        # Fallback for older PyTorch\n",
    "        return torch.cuda.amp.autocast(dtype=torch.float16)\n",
    "    \n",
    "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".webp\")\n",
    "\n",
    "def list_filenames(img_root):\n",
    "    return sorted([fn for fn in os.listdir(img_root) if fn.lower().endswith(IMG_EXTS)])\n",
    "# --- add this helper ---\n",
    "\n",
    "def _read_bytes(path: str) -> bytes:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def preload_image_bytes(filenames, root, max_workers: int = 12):\n",
    "    paths = [os.path.join(root, fn) for fn in filenames]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        data = list(ex.map(_read_bytes, paths))\n",
    "    return dict(zip(filenames, data))\n",
    "\n",
    "# REPLACE your get_num_layers(...) with this\n",
    "def get_num_layers(model):\n",
    "    \"\"\"\n",
    "    Return count of indexable hidden-state layers:\n",
    "      - If the model has a vision tower, return its depth.\n",
    "      - Otherwise, return decoder/text depth from model.config.\n",
    "    Assumes hidden_states = (emb, layer1, ..., layerL) → valid indices 1..L.\n",
    "    \"\"\"\n",
    "    vt = getattr(model, \"vision_tower\", None)\n",
    "    if vt is not None:\n",
    "        # Some VLMs keep the tower in a list/tuple\n",
    "        if isinstance(vt, (list, tuple)):\n",
    "            vt = vt[0]\n",
    "        cfg = getattr(vt, \"config\", None)\n",
    "        return int(getattr(cfg, \"num_hidden_layers\", getattr(cfg, \"num_layers\", 24)))\n",
    "    # Text-only models\n",
    "    cfg = getattr(model, \"config\", None)\n",
    "    return int(getattr(cfg, \"num_hidden_layers\", 26))\n",
    "\n",
    "\n",
    "_tokenizer_cache = {}\n",
    "_processor_cache = {}\n",
    "\n",
    "def _get_tokenizer(model_name):\n",
    "    if model_name not in _tokenizer_cache:\n",
    "        _tokenizer_cache[model_name] = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    return _tokenizer_cache[model_name]\n",
    "\n",
    "def _get_processor(model_name):\n",
    "    if model_name not in _processor_cache:\n",
    "        _processor_cache[model_name] = AutoProcessor.from_pretrained(model_name)\n",
    "    return _processor_cache[model_name]\n",
    "\n",
    "def _short(name: str):\n",
    "    return name.split(\"/\")[-1].replace(\":\", \"_\")\n",
    "\n",
    "def get_acts(\n",
    "    model, texts, layer, model_name, device,\n",
    "    *,\n",
    "    filenames=None, img_byte_cache=None,  # only for PaliGemma\n",
    "    batch_size=32, pool=\"mean\", use_amp=True, max_length=256\n",
    "):\n",
    "    \"\"\"Return (N, D) activations at a specific layer, pooled.\n",
    "       - Gemma: text forward, layer over decoder hs\n",
    "       - PaliGemma: vision_tower forward, layer over vision hs\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    feats = []\n",
    "\n",
    "    if not hasattr(model, \"vision_tower\"):\n",
    "        # ------- TEXT path (Gemma) -------\n",
    "        tok = _get_tokenizer(model_name)\n",
    "        with torch.inference_mode(), _amp_ctx(device, use_amp):\n",
    "            for start in range(0, len(texts), batch_size):\n",
    "                batch = texts[start:start+batch_size]\n",
    "                enc = tok(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "                enc = {k: v.to(device) for k, v in enc.items()}\n",
    "                out = model(**enc, output_hidden_states=True, return_dict=True)\n",
    "                hs = out.hidden_states[layer]  # (B, T, D)  layer index 1..L\n",
    "                mask = enc[\"attention_mask\"].unsqueeze(-1)  # (B, T, 1)\n",
    "                if pool == \"cls\":\n",
    "                    pooled = hs[:, 0, :]\n",
    "                elif pool == \"last\":\n",
    "                    last_idx = (enc[\"attention_mask\"].sum(dim=1) - 1).clamp(min=0)\n",
    "                    pooled = hs[torch.arange(hs.size(0), device=hs.device), last_idx, :]\n",
    "                else:  # mean\n",
    "                    summed = (hs * mask).sum(dim=1)\n",
    "                    denom = mask.sum(dim=1).clamp(min=1)\n",
    "                    pooled = summed / denom\n",
    "                feats.append(pooled.detach().float().cpu().numpy())\n",
    "                del out, enc, hs\n",
    "                torch.cuda.empty_cache()\n",
    "    else:\n",
    "        # ------- IMAGE path (PaliGemma vision tower) -------\n",
    "        assert filenames is not None and img_byte_cache is not None, \"PaliGemma path needs filenames & img_byte_cache.\"\n",
    "        proc = _get_processor(model_name)\n",
    "        # make sure the tower emits hidden states\n",
    "        try:\n",
    "            model.vision_tower.config.output_hidden_states = True\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        with torch.inference_mode(), _amp_ctx(device, use_amp):\n",
    "            for start in range(0, len(filenames), batch_size):\n",
    "                fnb = filenames[start:start+batch_size]\n",
    "                imgs = [Image.open(io.BytesIO(img_byte_cache[fn])).convert(\"RGB\") for fn in fnb]\n",
    "                enc = proc(images=imgs, return_tensors=\"pt\")\n",
    "                px = enc[\"pixel_values\"].to(device, non_blocking=True)\n",
    "                vout = model.vision_tower(pixel_values=px, output_hidden_states=True, return_dict=True)\n",
    "                hs = vout.hidden_states[layer]  # (B, N_tokens, D)  layer index 1..L\n",
    "                if pool == \"cls\" and hs.size(1) >= 1:\n",
    "                    pooled = hs[:, 0, :]\n",
    "                elif pool == \"last\" and hs.size(1) >= 1:\n",
    "                    pooled = hs[:, -1, :]\n",
    "                else:\n",
    "                    pooled = hs.mean(dim=1)  # robust across ViT/SigLIP-like towers\n",
    "                feats.append(pooled.detach().float().cpu().numpy())\n",
    "                del vout, enc, px, imgs, hs\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    return np.concatenate(feats, axis=0)\n",
    "# ========= end helpers =========\n",
    "\n",
    "\n",
    "# =======================\n",
    "#        MAIN LOOP\n",
    "# =======================\n",
    "model1_names = [\"google/gemma-2-2b\", \"google/paligemma2-3b-pt-224\"]\n",
    "model2_names = [\"google/gemma-2-2b\", \"google/paligemma2-3b-pt-224\"]\n",
    "data_name_list = ['cat', 'dog', 'human']\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "POOL = \"mean\"      # or \"cls\"/\"last\"\n",
    "USE_AMP = True\n",
    "experiment = LinearProbingExperiment(concept=\"cat_dog_classification\")\n",
    "\n",
    "for texts, labels, data_name in zip(texts_list, labels_list, data_name_list):\n",
    "    print(f\"\\n=== Concept: {data_name} ===\", flush=True)\n",
    "\n",
    "    # --- Per-concept image root + filenames + RAM cache (used only by PaliGemma) ---\n",
    "    IMG_ROOT = f\"../data/coco_val2017_{data_name}_binary_with_captions_balanced_images\"\n",
    "    filenames = list_filenames(IMG_ROOT)\n",
    "\n",
    "    # Align counts conservatively across texts/labels/images\n",
    "    N = min(len(texts), len(labels), len(filenames)) if len(filenames) > 0 else min(len(texts), len(labels))\n",
    "    if N < len(texts) or N < len(labels):\n",
    "        print(f\"(warn) Truncating to N={N} to keep text/label/image lengths aligned.\", flush=True)\n",
    "    texts   = texts[:N]\n",
    "    labels  = labels[:N]\n",
    "    filenames = filenames[:N]\n",
    "\n",
    "    img_byte_cache = preload_image_bytes(filenames, IMG_ROOT, max_workers=12) if len(filenames) else None\n",
    "\n",
    "    for model1_name in model1_names:\n",
    "        for model2_name in model2_names:\n",
    "            print(f\"\\nRunning linear probe: {data_name} | train on {_short(model1_name)} → test on {_short(model2_name)}\", flush=True)\n",
    "\n",
    "            model1 = load_models_with_eval(model1_name, DEVICE_1)\n",
    "            model2 = load_models_with_eval(model2_name, DEVICE_2)\n",
    "\n",
    "            # --- Shared layer range (decoder for Gemma, vision for PaliGemma) ---\n",
    "            L1 = get_num_layers(model1)\n",
    "            L2 = get_num_layers(model2)\n",
    "            layer_to_test = list(range(1, min(L1, L2) + 1))\n",
    "\n",
    "            all_results = []\n",
    "            train_accs, test_accs = [], []\n",
    "\n",
    "            for layer in layer_to_test:\n",
    "                with torch.inference_mode():\n",
    "                    act1 = get_acts(\n",
    "                        model1, texts, layer, model1_name, DEVICE_1,\n",
    "                        filenames=filenames if \"pali\" in model1_name.lower() else None,\n",
    "                        img_byte_cache=img_byte_cache if \"pali\" in model1_name.lower() else None,\n",
    "                        batch_size=BATCH_SIZE, pool=POOL, use_amp=USE_AMP\n",
    "                    )\n",
    "                    act2 = get_acts(\n",
    "                        model2, texts, layer, model2_name, DEVICE_2,\n",
    "                        filenames=filenames if \"pali\" in model2_name.lower() else None,\n",
    "                        img_byte_cache=img_byte_cache if \"pali\" in model2_name.lower() else None,\n",
    "                        batch_size=BATCH_SIZE, pool=POOL, use_amp=USE_AMP\n",
    "                    )\n",
    "\n",
    "                # === Run probe experiment ===\n",
    "                results = experiment.run_experiment(\n",
    "                    act1, labels,\n",
    "                    act2, labels\n",
    "                )\n",
    "                all_results.append(results)\n",
    "\n",
    "                tr = results[1]['sklearn']['train_acc']\n",
    "                te = results[1]['sklearn']['test_acc']\n",
    "                train_accs.append(tr); test_accs.append(te)\n",
    "\n",
    "                print(f\"[{data_name}] layer {layer:02d} | train_acc={tr:.4f} | test_acc={te:.4f}\")\n",
    "                # Print (optional) report line\n",
    "                # print(results[1]['sklearn']['classification_report'])\n",
    "\n",
    "                # ---- Save results ----\n",
    "                os.makedirs(f\"../output/{data_name}\", exist_ok=True)\n",
    "                tag = f\"{_short(model1_name)}_{_short(model2_name)}_img4pali\"\n",
    "                out_json = f\"../output/{data_name}/linear_probing_results_layer{layer:02d}_{tag}.json\"\n",
    "                try:\n",
    "                    experiment.save_results(results, out_json)\n",
    "                except Exception as e:\n",
    "                    # Fallback minimal JSON if your experiment wrapper expects different fields\n",
    "                    print(f\"(warn) save_results failed ({e}); writing minimal JSON.\")\n",
    "                    ultra = {\n",
    "                        \"meta\": {\"data\": data_name, \"layer\": int(layer),\n",
    "                                 \"train_model\": model1_name, \"test_model\": model2_name},\n",
    "                        \"train_acc\": float(tr),\n",
    "                        \"test_acc\":  float(te)\n",
    "                    }\n",
    "                    with open(out_json.replace(\".json\", \"_minimal.json\"), \"w\") as f:\n",
    "                        json.dump(ultra, f, indent=2)\n",
    "\n",
    "                # ---- Save misclassified examples (use current 'texts') ----\n",
    "                if 'y_test' in results[1]['sklearn'] and 'y_pred' in results[1]['sklearn']:\n",
    "                    mis_indices = [i for i, (yt, yp) in enumerate(zip(\n",
    "                        results[1]['sklearn']['y_test'], results[1]['sklearn']['y_pred']\n",
    "                    )) if yt != yp]\n",
    "                    mis_info = [\n",
    "                        {\n",
    "                            'text': texts[i],\n",
    "                            'true_label': int(results[1]['sklearn']['y_test'][i]),\n",
    "                            'pred_label': int(results[1]['sklearn']['y_pred'][i])\n",
    "                        }\n",
    "                        for i in mis_indices\n",
    "                    ]\n",
    "                    mis_dir = f\"../output/{data_name}/{tag}\"\n",
    "                    os.makedirs(mis_dir, exist_ok=True)\n",
    "                    with open(os.path.join(mis_dir, f\"misclassified_layer_{layer:02d}_img4pali.json\"), \"w\") as f:\n",
    "                        json.dump(mis_info, f, indent=2)\n",
    "                else:\n",
    "                    print(\"(warn) 'y_test' or 'y_pred' not found; misclassifications not saved.\")\n",
    "\n",
    "                del act1, act2, results\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "            # ===== Plot Train and Test Accuracy Across Layers =====\n",
    "            layers_ = layer_to_test\n",
    "            plt.figure(figsize=(7, 4))\n",
    "            plt.plot(layers_, train_accs, label='Train')\n",
    "            plt.plot(layers_, test_accs,  label='Test', linestyle=\"--\")\n",
    "            plt.xlabel('Layer'); plt.ylabel('Accuracy')\n",
    "            plt.title(f\"{data_name} — Linear Probe Accuracy by Layer\\ntrain={_short(model1_name)} → test={_short(model2_name)}\\n_img4pali\")\n",
    "            plt.ylim(0.0, 1.0); plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout()\n",
    "            fig_dir = f\"../figs_tabs/{data_name}/\"\n",
    "            os.makedirs(fig_dir, exist_ok=True)\n",
    "            plt.savefig(os.path.join(fig_dir, f\"acc_by_layer_{_short(model1_name)}_{_short(model2_name)}_img4pali.png\"), dpi=200)\n",
    "            plt.show(); plt.close()\n",
    "\n",
    "            # free models\n",
    "            del model1, model2\n",
    "            gc.collect(); torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
